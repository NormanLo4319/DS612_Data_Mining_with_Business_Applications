# First of all, if you have not install the package "ISLR" on your machine yet, you will need to run the following command.
install.packages("ISLR")
# Once the package is installed, you can get access to the libraries within the package
library(MASS)
library(ISLR)
# Within the MASS library, there is a data set named "Boston".
# We will be using this data set for our exercise today.
# Boston is the source of Data
?Boston
# Before our analysis, we would like to visualize our data
# For instance, we can plot two columns in the data set, medv (median value of owner-occupied homes)
# and lstat (lower status of the population(%))
plot(medv~lstat,Boston)
# Simple Linear Regression Line
# If we believe that there is a linear relationship between medv and lstat, we can build a simiple regression model with lm()
?lm
# The specification of our model is medv = beta0 + beta1*(lstat) and we are going to save the model into fit1
fit1 <- lm(medv~lstat,data = Boston)
View(fit1)
# Once the model is saved into a variable, we can then print the summary of it.
summary(fit1)
# We also plot the regression line and visualize the fitted line
# The abline function will take two values a = intercept of a straight line and b = slope of a stright line
abline(fit1,col="red")
# We can use the names() to check the attribute in the fitted model
names(fit1)
View(fit1)
View(fit1)
# We can check the confidence interval for our coefficients by using the confint()
confint(fit1)
# Setting the 99% confidence interval
x <- confint(fit1,level=0.99)
x
# If any question about the function, always make use of the help function
?confint
?predict
# Use the predict function to make prediction of medv
predict(fit1,data.frame(lstat = c(5,10,15)),interval = "confidence",level = .99)
# We can check if adding a new variable (age) to the model specification would help explaining medv
fit2 <- lm(medv~lstat+age,data= Boston)
summary(fit2)
# We can also add all the variables from the data set into our model by use "."
fit3 <- lm(medv~.,data = Boston)
summary(fit3)
# If we want to drop some variables from the data set, we can use the negative sign "-"
fit4 <- lm(medv~.-age-indus,data = Boston)
summary(fit4)
# Non-linear Transformations or Interation effects
# Let's add lstat*age interation effect
fit5 <- lm(medv~lstat*age,data = Boston)
# If you want to keep the interation effect only - you need to use lstat:age
summary(fit5)
# You can also add a squared term to the model
# medv = b0 + b1(lstat) + b2(lstat^2)
fit6 <- lm(medv~lstat+I(lstat^2),data = Boston)
summary(fit6)
abline(fit6,col="blue")
# The reason we are using the I() is because we need the function to specify the formula (lstat^2)
# When we need to specify the mathematic operator in our model, we need to use I() to interpret within the model.
?I
# Creating a polynomial specification, we can use the function poly()
fit7 <- lm(medv~poly(lstat,5),data = Boston)
summary(fit7)
# How to deal with Qualitative Predictors - Dummy Variables
# In this exercise, we are using the data set "Carseats" from the ISLR library
?Carseats
# Use the names() function to print the column names in the data frame
names(Carseats)
# Use the summary() function to print the discriptive static summary
summary(Carseats)
# We can also use the lm() function to run the linear model with catagorical varaibles
fit8 <- lm(Sales~.+Income:Advertising+Age:Price,data = Carseats)
summary(fit8)
knitr::opts_chunk$set(echo = TRUE)
# Loading the data
Auto = read.csv("./Data/Textbook_Data/Auto.csv", header=TRUE, na.strings="?")
# Loading the data
Auto = read.csv("Data/Textbook_Data/Auto.csv", header=TRUE, na.strings="?")
getwd()
getwd()
# Loading the data
Auto = read.csv("Teaching/DS612/DS612_Data_Mining_with_Business_Applications/Data/Textbook_Data/Auto.csv", header=TRUE, na.strings="?")
unlink('C:/Users/lokma/Desktop/Teaching/DS612/DS612_Assignment_1_Key_cache', recursive = TRUE)
# Loading the data
Auto = read.csv("DS612_Data_Mining_with_Business_Applications/Data/Textbook_Data/Auto.csv", header=TRUE, na.strings="?")
yum -y install texlive-framed
$sudo yum -y install texlive-extras
sudo yum -y install texlive-extras
install.packages(c('tinytex', 'rmarkdown'))
install.packages(c("tinytex", "rmarkdown"))
# Practice with crime data set
AutoData <- read.xlsx("Data/Practice_Data/crime_data.xlsx",header = TRUE, na.string="?")
# Practice with crime data set
Crime <- read.xlsx("Data/Practice_Data/crime_data.xlsx",header = TRUE, na.string="?")
# Install read.xlsx package
install.packages("xlsx")
library(xlsx)
# Practice with crime data set
Crime <- read.xlsx("Data/Practice_Data/crime_data.xlsx",header = TRUE, na.string="?")
# Practice with crime data set
Crime <- read.xlsx("Data/Practice_Data/crime_data.xlsx",header=TRUE)
# Practice with crime data set
Crime <- read.xlsx("Data/Practice_Data/crime_data.xlsx",header = TRUE, na.string="?")
library(xlsx)
library("xlsx")
# Install read.xlsx package
install.packages("readxl")
library("readxl")
# Practice with crime data set
Crime <- read_excel("Data/Practice_Data/crime_data.xlsx",header = TRUE, na.string="?")
# Practice with crime data set
Crime <- read_excel("Data/Practice_Data/crime_data.xlsx")
View(Crime)
# Pairs Plot
pairs(Crime)
# Pairs Plot
pairs(Crime)
View(Crime)
names(Crime)
Attach(Crime)
attach(Crime)
# Pairs Plot
pairs(violent crime, murder and non-negligent manslaughter)
# Pairs Plot
pairs(violent_crime, murder_and_non-negligent_manslaughter)
# Pairs Plot
pairs("violent_crime", "murder_and_non-negligent_manslaughter")
# Practice with food_env data set
food <- read_csv("Data/Practice_Data/food_env_data.csv", header = TRUE, na.string="?")
# Practice with food_env data set
food <- read.csv("Data/Practice_Data/food_env_data.csv", header = TRUE, na.string="?")
names(food)
attach(food)
# Pairs Plot
pairs(Survey.Obesity, Survey.Diabetes)
# Pairs Plot
plot(Survey.Obesity, Survey.Diabetes)
# Practice with food_env data set
food <- read.csv("Data/Textbook_Data/Credit.csv", header = TRUE, na.string="?")
# Practice with food_env data set
Credit <- read.csv("Data/Textbook_Data/Credit.csv", header = TRUE, na.string="?")
names(Credit)
attach(Credit)
# Pairs Plot
pairs(Credit)
# We are going to practice with the Credit data set
Credit <- read.csv("Data/Textbook_Data/Credit.csv", header = TRUE, na.string="?")
names(Credit)
attach(Credit)
pairs(Credit["Balance", "Gender", "Age", "Ethnicity"])
pairs(Credit)
cor(Balance, Age)
#
fit1 <- lm(Balance~Age, data=Credit)
summary(fit1)
plot(Balance~Age)
Credit[1:]
Credit[1]
Credit[2]
return corr
corr.append(cor(Balance, Credit[i]))
corr <- append(cor(Balance, Credit[i]))
# Let's check the correlation between all the variables with Balance.
for (i in 2:12){
corr <- append(cor(Balance, Credit[i]))
}
cor(Balance, Credit[2])
corr = []
corr = ['']
corr <- ['']
corr <- c()
# Let's check the correlation between all the variables with Balance.
for (i in 2:12){
result <- cor(Balance, Credit[i]))
corr <- append(corr, result)
}
result <- cor(Balance, Credit[i])
# Let's check the correlation between all the variables with Balance.
for (i in 2:12){
result <- cor(Balance, Credit[i])
corr <- append(corr, result)
}
corr <- c()
# Let's check the correlation between all the variables with Balance.
for (i in 2:12){
result <- cor(Balance, Credit[i])
corr <- append(corr, result)
}
corr
View(result)
View(result)
cor(Balance, Credit[8])
View(Credit)
View(Credit)
# Try to use the linear model to fit the data.
fit1 = lm(Balance~Rating+Cards, data=Credit)
summary(fit1)
View(Credit)
# Seems like Card is not statistically significant in the model
# Let's try the third highest correlated quantitative variable, income.
fit2 = lm(Balance~Rating+Income, data=Credit)
summary(fit2)
# Let's try to add a qualitative variable (Gender) into our model.
fit3 = lm(Balance~Rating+Income+Gender, data=Credit)
summary(fit3)
# Let's try Ethnicity this time.
fit4 <- lm(Balance~Rating+Income+Ethnicity, data=Credit)
# Let's try to add a qualitative variable (Gender) into our model.
fit3 <- lm(Balance~Rating+Income+Gender, data=Credit)
summary(fit4)
# Lastly, let's try Student.
fit5 <- lm(Balance~Rating+Income+Student, data=Credit)
summary(fit5)
# Let suppose we are satisfy with the current model specification and we would like to plot
# the regression line to see how it fit between Balance and Rating.
plot(Rating, Balance)
abline(fit5)
abline(fit5, col='red')
abline(fit5, lwd=3, col='red')
abline(fit5, lwd=2, col='red')
plot(Rating, Balance, col='blue')
plot(Rating, Balance, pch='+')
plot(Rating, Balance, pch='20')
plot(Rating, Balance, pch=1:20)
plot(Rating, Balance, pch='+')
par(mfrow=c(2,2))
plot(fit5)
plot(predict(fit5), residuals(fit5))
plot(predict(fit5), rstudent(fit5))
plot(hatvalues(lm.fit))
plot(hatvalues(fit5))
which.max(hatvalues(fit5))
# Suppose we suspect that there may be multicollinearity between Income and Student
# We can check for multicollinearity by using the VIF test
vif(fit5)
# Suppose we suspect that there may be multicollinearity between Income and Student
# We can check for multicollinearity by using the VIF test
install.packages(car)
# Suppose we suspect that there may be multicollinearity between Income and Student
# We can check for multicollinearity by using the VIF test
library(car)
# Suppose we suspect that there may be multicollinearity between Income and Student
# We can check for multicollinearity by using the VIF test
install.packages(car)
# Suppose we suspect that there may be multicollinearity between Income and Student
# We can check for multicollinearity by using the VIF test
install.packages("car")
library(car)
vif(fit5)
library(MASS)
library(ISLR)
?Boston
boston_df <- read.csv('Data/Textbook_Data/Boston.csv')
View(boston_df)
# Before our analysis, we would like to visualize our data
# For instance, we can plot two columns in the data set, medv (median value of owner-occupied homes)
# and lstat (lower status of the population(%))
plot(medv~lstat,Boston)
# Before our analysis, we would like to visualize our data
# For instance, we can plot two columns in the data set, medv (median value of owner-occupied homes)
# and lstat (lower status of the population(%))
plot(medv~lstat,Boston)
attach(Boston)
# The specification of our model is medv = beta0 + beta1*(lstat) and we are going to save the model into fit1
fit1 <- lm(medv~lstat)
# Once the model is saved into a variable, we can then print the summary of it.
summary(fit1)
# We also plot the regression line and visualize the fitted line
# The abline function will take two values a = intercept of a straight line and b = slope of a stright line
abline(fit1,col="red")
# We also plot the regression line and visualize the fitted line
# The abline function will take two values a = intercept of a straight line and b = slope of a stright line
abline(fit1,lwd=3, col="red")
# We can check the confidence interval for our coefficients by using the confint()
confint(fit1)
# Setting the 99% confidence interval
x <- confint(fit1,level=0.99)
x
View(boston_df)
# Use the predict function to make prediction of medv
predict(fit1,data.frame(lstat = c(5,10,15)),interval = "confidence",level = .99)
# Non-linear Transformations or Interation effects
# Let's add lstat*age interation effect
fit5 <- lm(medv~lstat*age,data = Boston)
# If you want to keep the interation effect only - you need to use lstat:age
summary(fit5)
# Non-linear Transformations or Interation effects
# Let's add lstat*age interation effect
fit5 <- lm(medv~lstat:age,data = Boston)
# If you want to keep the interation effect only - you need to use lstat:age
summary(fit5)
# Practice with food_env data set
Credit <- read.csv("Data/Textbook_Data/Credit.csv", header = TRUE, na.string="?")
names(Credit)
attach(Credit)
# Pairs Plot
pairs(Credit)
# Plot the data between Balance and Age
plot(Age, Balance)
?cor
# Create a for loop to get all the correlation between Balance and other variables.
corr <- c()
for (i in 2:12){
result <- cor(Balance, Credit[i])
corr <- append(result)
}
corr <- append(corr, result)
for (i in 2:12){
result <- cor(Balance, Credit[i])
corr <- append(corr, result)
}
corr
print(result)
for (i in 2:12){
result <- cor(Balance, Credit[i])
print(result)
corr <- append(corr, result)
}
# Create a for loop to get all the correlation between Balance and other variables.
corr <- c()
for (i in 2:12){
result <- cor(Balance, Credit[i])
print(result)
corr <- append(corr, result)
}
# Create a for loop to get all the correlation between Balance and other variables.
corr <- c()
for (i in 2:12){
result <- trycatch(cor(Balance, Credit[i])),
error=function(e)
paste("NA")
print(result)
corr <- append(corr, result)
}
# Create a for loop to get all the correlation between Balance and other variables.
corr <- c()
for (i in 2:12){
result <- trycatch(cor(Balance, Credit[i])),
error=function(e)
paste("NA"))
print(result)
corr <- append(corr, result)
}
# Create a for loop to get all the correlation between Balance and other variables.
corr <- c()
for (i in 2:12){
result <- trycatch(cor(Balance, Credit[i]),
error=function(e)
paste("NA"))
print(result)
corr <- append(corr, result)
}
for (i in 2:12){
result <- tryCatch(cor(Balance, Credit[i]),
error=function(e)
paste("NA"))
print(result)
corr <- append(corr, result)
}
corr
# Create a for loop to get all the correlation between Balance and other variables.
corr <- c()
for (i in 2:12){
result <- tryCatch(cor(Balance, Credit[i]), error=function(e)
paste("NA"))
print(result)
corr <- append(corr, result)
}
corr
View(Credit)
# Let's try the forward selection method
fit1 <- lm(Balance~Rating, data=Credit)
summary(fit1)
# Let's try to add the second highest correlated variable Limit
fit2 <- lm(Balance~Rating+Limit, data=Credit)
summary(fit2)
# Now, let's try to add the third highest correclated variable Income
fit3 <- lm(Balance~Rating+Income, data=Credit)
summary(fit3)
# Now, let's try adding Card to the model
fit4 <- lm(Balance~Rating+Income+Card, data=Credit)
# Now, let's try adding Card to the model
fit4 <- lm(Balance~Rating+Income+Cards, data=Credit)
summary(fit4)
# Let's try adding gender to the model.
fit5 <- lm(Balance~Rating+Income+Gender, data=Credit)
summary(fit5)
# Let's try adding Student to the model.
fit6 <- lm(Balance~Rating+Income+Student, data=Credit)
summary(fit6)
# Let's try Married to the model
fit7 <- lm(Balance~Rating+Income+Student+Married, data=Credit)
summary(fit7)
# Let's try adding Ethnicity to the model.
fit8 <- lm(Balance~Rating+Income+Student+Ethnicity, data=Credit)
summary(fit8)
final_fit <- lm(Balance~Rating+Income+Student, data=Credit)
plot(Balance, Rating)
plot(Balance, Income)
plot(Balance, Student)
plot(Rating, Balance)
plot(Income, Balance)
plot(Student, Balance)
# Plotting the regression line
abline(final_fit, lwd=3, col="red")
# Check again the data between Balance and each of the variable in the model
plot(Rating, Balance)
# Plotting the regression line
abline(final_fit, lwd=3, col="red")
# Plotting the regression line
abline(fit6, lwd=3, col="blue")
# Divides the plotting region into a 2x2 grid of panels.
par(mfrow=c(2,2))
plot(fit6)
# We can also use the residuals() function to compute the residuals from the fitted model.
plot(predict(fit6), residuals(fit6))
plot(predict(fit6), rstudent(fit6))
# We can also compute the Leverage statistics for any number of predictors using the hatvalues() function
plot(hatvalues(lm.fit))
# We can also compute the Leverage statistics for any number of predictors using the hatvalues() function
plot(hatvalues(fit6))
# We can also find out the largest leverage statistic observation in the model.
which.max(hatvalues(fit6))
# One of the common test for multicollinear for multivariable linear regression is VIF
library(car)
vif(lm.fit)
vif(fit6)
predict(fit6, ,interval = "confidence",level = .99)
predict(fit6, interval="confidence", level=0.99)
# At this point, we can try to make a prediction of Balance based on our fitted model.
predict(fit6, interval="confidence", level=0.99, se.fit=TRUE)
new_data <- data.frame(rating=c(680, 480, 280))
new_data
new_data <- data.frame(rating<-c(680, 480, 280), income<-c(55, 80, 130))
new_data
new_data <- (680, 80, 1)
predict(fit6, new_data, interval="confidence", level=0.99)
new_data <- data.frame("rating"<-c(680, 480, 280), "income"<-c(55, 80, 130), 'student'<-c("Yes", "Yes", "No"))
new_data
View(new_data)
View(new_data)
rm(new_data)
new_data <- data.frame("rating"<-c(680, 480, 280), "income"<-c(55, 80, 130), 'student'<-c("Yes", "Yes", "No"))
new_data
View(new_data)
rm(new_data)
new_data <- data.frame("rating"<-c(680, 480, 280), "income"<-c(55, 80, 130), "student"<-c("Yes", "Yes", "No"))
str(x)
View(new_data)
str(new_data)
new_data
rm(new_data)
new_data <- data.frame("r"<-c(680, 480, 280), "i"<-c(55, 80, 130), "s"<-c("Yes", "Yes", "No"))
str(new_data)
new_data
r <- c(680, 480, 280)
i <- c(55, 80, 130)
s <- c("Yes", "Yes", "No")
rm(new_data)
new_data <- data.frame(r,i,s)
str(new_data)
new_data
predict(fit6, new_data, interval="confidence", level=0.99)
