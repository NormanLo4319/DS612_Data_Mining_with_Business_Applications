write.xlsx(Default, 'Data\\Textbook_Data\\Default.xlsx', row.names=FALSE)
# Call out the Smarket data set
names(Smarket)
# print summary of the data set
summary(Smarket)
# Export dataset to csv file
write.csv(Smarket, 'Data\\Textbook_Data\\Smarket.csv', row.names=FALSE)
# Learning more about the data set
?Smarket
# Plot the pairs correlation of the data
pairs(Smarket,col=Smarket$Direction)
# Logistic Regression
# Use the General Linear Model function to build the logistic regression model.
glm.fit <- glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,
data=Smarket,family=binomial)
# Print the summary of the fitted model
summary(glm.fit)
# Generate the probabilyt function based on the fitted model for prediction
glm.probs <- predict(glm.fit,type="response")
# Use the probability function to predict the first five observations in the data
# It will return the probability for going up the next day
glm.probs[1:5]
# We can also use the ifelse() function to change the return values
# If the probabiliyt is over 50%, it will return "Up", else it will return "Down"
glm.pred <- ifelse(glm.probs>0.5,"Up","Down")
# Compare the return values to the previous
# As you observed, the probability function is nested to this new prediction function
glm.pred[1:5]
# We can attach the Smarket data set for convenience
attach(Smarket)
# Check the model prediction to the actual data
table(glm.pred,Direction)
# We can measure the accuracy of the model prediction by taking the mean of the correct results
mean(glm.pred == Direction)
# We can also check the error of the model prediction by reversing the measure
mean(glm.pred != Direction)
# For better accuracy check, we are going to split our data into training and testing sets
# Make training and testing set
# Training data will be the data with year before 2005
train <- Year<2005
# Use the glm() function to build the logistic regression model on the training data
glm.fit <- glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,
data=Smarket,family=binomial, subset=train)
summary(glm.fit)
# Create the probability function by using the fitted model
glm.probs <- predict(glm.fit,newdata=Smarket[!train,],type="response")
# Create the prediction function by defining the results with threshold 50% or above
glm.pred <- ifelse(glm.probs >0.5,"Up","Down")
# Compare the prediction with the testing data
Direction.2005 <- Smarket$Direction[!train]
# Present the comparison in a matrix table
table(glm.pred,Direction.2005)
# Calculate the accuracy for the prediction
mean(glm.pred == Direction.2005)
# We can also find the error rate for the prediction
mean(glm.pred != Direction.2005)
# In the previous model, we found that the lag1 and lag2 are the best predictors in the model
# Let's build a smaller model with just lag1 and lag2 for the logistic regression model
glm.fit <- glm(Direction~Lag1+Lag2,
data=Smarket,family=binomial, subset=train)
glm.probs <- predict(glm.fit,newdata=Smarket[!train,],type="response")
glm.pred <- ifelse(glm.probs >0.5,"Up","Down")
table(glm.pred,Direction.2005)
mean(glm.pred == Direction.2005)
mean(glm.pred != Direction.2005)
# We are going to use the Linear Discriminant Analysis
# The LDA requires the library MASS
require(MASS)
# Linear Discriminant Analysis
# Using lda() function for the linear discriminant analysis with lag1 and lag2
lda.fit <- lda(Direction~Lag1+Lag2,data=Smarket, subset=Year<2005)
# Check the model fit
lda.fit
# Plot the model fit
plot(lda.fit)
# Define the testing data year = 2005 for testing
Smarket.2005 <- subset(Smarket,Year==2005)
# Use the fitted model to make the prediction using the testing data
lda.pred <- predict(lda.fit,Smarket.2005)
# Predict the first 5 observations
lda.pred[1:5,]
# Predict the first 5 observations
lda.pred[1:5]
# Predict the first 5 observations
lda.pred[1:5,]
# Check the class in the prediction function
class(lda.pred)
# Show the prediction in a data frame
data.frame(lda.pred)[1:5,]
# Predict the first 5 observations
print(lda.pred[1:5,])
# Predict the first 5 observations
lda.pred[1:5]
# Predict the first 5 observations
lda.pred$class[1:5]
# Predict the first 5 observations
lda.pred$class[1:5,]
# Predict the first 5 observations
lda.pred$class[1:5]
# Show the prediction in a data frame
data.frame(lda.pred)[1:5,]
# Show the prediction in a data frame
data.frame(lda.pred)[1:5]
# Show the prediction in a data frame
data.frame(lda.pred)[1:5,]
# Predict the first 5 observations
lda.pred$class[1:5,]
# Predict the first 5 observations
lda.pred[1:5,]
# Check the class in the prediction function
class(lda.pred)
# Check the class in the prediction function
class(lda.pred)
# Show the prediction in a data frame
data.frame(lda.pred)[1:5,]
# Compare the prediction and testing data in a matrix table
table(lda.pred$class,Smarket.2005$Direction)
# Check the accuracy from the LDA model
mean(lda.pred$class==Smarket.2005$Direction)
# Quadratic Discriminant Analysis
# Using qda() function for the linear discriminant analysis with lag1 and lag2
qda.fit <- qda(Direction~Lag1+Lag2,data=Smarket, subset=Year<2005)
# Check the model fit
qda.fit
# Plot the model fit
plot(qda.fit)
# Plot the model fit
library(klaR)
# Plot the model fit
require(MASS)
library(klaR)
# Plot the model fit
install.packages(“klaR”)
# Plot the model fit
install.packages('klaR')
library(klaR)
partimat(Direction~Lag1+Lag2,data=Smarket,method="qda")
# Define the testing data year = 2005 for testing
Smarket.2005 <- subset(Smarket,Year==2005)
# Use the fitted model to make the prediction using the testing data
qda.pred <- predict(qda.fit,Smarket.2005)
# Predict the first 5 observations
qda.pred[1:5,]
# Predict the first 5 observations
qda.pred[1:5]
# Predict the first 5 observations
qda.pred$class[1:5]
# Check the class in the prediction function
class(qda.pred)
# Show the prediction in a data frame
data.frame(lda.pred)[1:5,]
# Predict the first 5 observations
qda.pred$class[1:5,:]
# Predict the first 5 observations
qda.pred[1:5,:]
# Predict the first 5 observations
qda.pred[1:5,]
print(qda.pred)
# Predict the first 5 observations
lda.pred$class[1:5]
# Show the prediction in a data frame
data.frame(lda.pred)[1:5,]
# Compare the prediction and testing data in a matrix table
table(qda.pred$class,Smarket.2005$Direction)
# Check the accuracy from the LDA model
mean(qda.pred$class==Smarket.2005$Direction)
# K-Nearest Neighbors
# The KNN method, we need to import library 'class'
library(class)
# Check the knn() function
?knn
# Attached the Smarket data set
attach(Smarket)
# Creating the lag variable, which includes lag1 and lag2
Xlag <- cbind(Lag1,Lag2)
# Create the training data for data before the year 2005
train <- Year<2005
# Use the knn() function to input the training set, testin set, and response variable (Direction)
# Note that we give the parameter k = 1, which defines the number of neighbor
knn.pred <- knn(Xlag[train,],Xlag[!train,],Direction[train],
k=1, prob=FALSE)
# Compare the prediction and the testing data in a matrix table
table(knn.pred,Direction[!train])
# Check the accuracy of the fitted model
mean(knn.pred == Direction[!train])
# Check the error rate of the fitted model
mean(knn.pred != Direction[!train])
# Once the package is installed, you can get access to the libraries within the package
library(MASS)
library(ISLR)
# Within the MASS library, there is a data set named "Boston".
# We will be using this data set for our exercise today.
# Boston is the source of Data
?Boston
?Default
row1 = c(1, 2, 3, 4, 5, 6)
row2 = c(2, 4, 6, 8, 10, 12)
row3 = c(1, 3, 5, 7, 9, 11)
row4 = c(9, 5, 2, 4, 6, 1)
row5 = c(3, 2, 4, 7, 9, 10)
test = c(2, 2, 3, 3, 6, 6)
euclidean <- function(a, b) {
distance <- sqrt((a[1]-b[1])**2 + (a[2]-b[2])**2 + (a[3]-b[3])**2 +
(a[4]-b[4])**2 + (a[5]-b[5])**2 + (a[6]-b[6])**2)
return(distance)
}
euclidean(row1, test)
for i in range(1:5){
print(i)
}
for (i in range(1:5)) {
print(i)
}
for (i in (1:5)) {
print(i)
}
}
for (i in (1:5)) {
print(sprintf("Row%d", i)
}
print(sprintf("Row%d", i))
for (i in (1:5)) {
print(sprintf("Row%d", i))
}
for (i in (1:5)) {
print(sprintf("Row%d", i))
result = euclidean('Row%d', i, test)
print(result)
}
for (i in (1:5)) {
print(sprintf("Row%d", i))
result = euclidean(sprintf('Row%d', i), test)
print(result)
}
for (i in (1:5)) {
print(sprintf("Row%d", i))
result = euclidean(sprintf("Row%d", i), test)
print(result)
}
for (i in (1:5)) {
print(sprintf("Row%d", i))
result = euclidean(assign(sprintf("Row%d", i)), test)
print(result)
}
result = euclidean(as.name(sprintf("Row%d", i)), test)
for (i in (1:5)) {
print(sprintf("Row%d", i))
result = euclidean(as.name(sprintf("Row%d", i)), test)
print(result)
}
print(as.name('Row1'))
print(assign('Row1'))
print(eval(parse(text='Row1'))
print(eval(parse(text='Row1')))
eval(parse(text='Row1'))
eval(parse(text='row1'))
for (i in (1:5)) {
print(sprintf("Row%d", i))
result = euclidean(eval(parse(sprintf("row%d", i))), test)
print(result)
}
result = euclidean(eval(parse(text=sprintf("row%d", i))), test)
for (i in (1:5)) {
print(sprintf("Row%d", i))
result = euclidean(eval(parse(text=sprintf("row%d", i))), test)
print(result)
}
matrix = rbind(row1, row2, row3, row4, row5)
View(matrix)
matrix[1,1]
matrix[1,]
matrix[1,][1]
for (i in (1:5)) {
print(matrix[i,])
for (j in (1:6)) {
print(matrix[i,][j])
}
}
for (i in (1:5)) {
print(matrix[i,])
result = euclidean(matrix[i,], test)
print(result)
}
len(matrix)
lenght(matrix)
dim(matrix)
dim(matrix)[1]
range(dim(matrix)[1])
# Let suppose we are trying to get the mean, sd, and range for the 5 rows of data.
for (i in 1:dim(matrix[1])){
print(i)
m = mean(eval(parse(text=sprintf("row%d", i))))
s = sd(eval(parse(text=sprintf("row%d", i))))
r = range(eval(parse(text=sprintf("row%d", i))))
return(m, s, r)
}
# Let suppose we are trying to get the mean, sd, and range for the 5 rows of data.
for (i in 1:dim(matrix)[1]){
print(i)
m = mean(eval(parse(text=sprintf("row%d", i))))
s = sd(eval(parse(text=sprintf("row%d", i))))
r = range(eval(parse(text=sprintf("row%d", i))))
return(m, s, r)
}
# Let suppose we are trying to get the mean, sd, and range for the 5 rows of data.
for (i in 1:dim(matrix)[1]){
print(i)
m = mean(eval(parse(text=sprintf("row%d", i))))
s = sd(eval(parse(text=sprintf("row%d", i))))
r = range(eval(parse(text=sprintf("row%d", i))))
return c(m, s, r)
}
# Let suppose we are trying to get the mean, sd, and range for the 5 rows of data.
for (i in 1:dim(matrix)[1]){
print(i)
m = mean(eval(parse(text=sprintf("row%d", i))))
s = sd(eval(parse(text=sprintf("row%d", i))))
r = range(eval(parse(text=sprintf("row%d", i))))
result = c(m, s, r)
}
# Let suppose we are trying to get the mean, sd, and range for the 5 rows of data.
for (i in 1:dim(matrix)[1]){
print(i)
m = mean(eval(parse(text=sprintf("row%d", i))))
s = sd(eval(parse(text=sprintf("row%d", i))))
r = range(eval(parse(text=sprintf("row%d", i))))
result = c(m, s, r)
print(result)
}
# Let suppose we are trying to get the mean, sd, and range for the 5 rows of data.
for (i in 1:dim(matrix)[1]){
print(sprintf("row%d",i))
m = mean(eval(parse(text=sprintf("row%d", i))))
s = sd(eval(parse(text=sprintf("row%d", i))))
r = range(eval(parse(text=sprintf("row%d", i))))
result = c(m, s, r)
print(sprintf("Mean: %s", result[1]))
print(sprintf("Standard Deviation: %s", result[2]))
print(sprintf("Range: [ %s", result[3], ", %s", result[4], "]"))
}
sprintf("Range: [ %s", result[3], ", %s", result[4], "]")
sprintf("Range: [ %s , %s", result[3], "]")
sprintf("Range: [ %s , %s", result[3], result[4] "]")
sprintf("Range: [", result[3], ", ", result[4] "]")
sprintf("Range: [", result[3], ", ", result[4], "]")
paste0("Range: [", result[3], ", ", result[4], "]")
# Let suppose we are trying to get the mean, sd, and range for the 5 rows of data.
for (i in 1:dim(matrix)[1]){
print(sprintf("row%d",i))
m = mean(eval(parse(text=sprintf("row%d", i))))
s = sd(eval(parse(text=sprintf("row%d", i))))
r = range(eval(parse(text=sprintf("row%d", i))))
result = c(m, s, r)
print(sprintf("Mean: %s", result[1]))
print(sprintf("Standard Deviation: %s", result[2]))
print(paste0("Range: [", result[3], ", ", result[4], "]"))
}
for (i in (1:5)) {
print(sprintf("Row%d", matrix[i,]))
result = euclidean(matrix[i,], test)
print(result)
}
print(sprintf("Row%d", i): matrix[i,])
for (i in (1:5)) {
print(matrix[i,])
result = euclidean(matrix[i,], test)
print(result)
}
# Let suppose we are trying to get the mean, sd, and range for the 5 rows of data.
for (i in 1:dim(matrix)[1]){
print(sprintf("row%d",i))
m = mean(eval(parse(text=sprintf("row%d", i))))
s = sd(eval(parse(text=sprintf("row%d", i))))
r = range(eval(parse(text=sprintf("row%d", i))))
result = c(m, s, r)
print(sprintf("Mean: %.3f", result[1]))
print(sprintf("Standard Deviation: %.3f", result[2]))
print(paste0("Range: [", result[3], ", ", result[4], "]"))
}
# Import ISLR library
require(ISLR)
# Importing xlsx package for exporting data set to xlsx format
install.packages('xlsx')
library("xlsx")
names(Default)
?Default
write.xlsx(Default, 'Data\\Textbook_Data\\Default.xlsx', row.names=FALSE)
# Call out the Smarket data set
names(Smarket)
# print summary of the data set
summary(Smarket)
# Export dataset to csv file
write.csv(Smarket, 'Data\\Textbook_Data\\Smarket.csv', row.names=FALSE)
# Learning more about the data set
?Smarket
# Plot the pairs correlation of the data
pairs(Smarket,col=Smarket$Direction)
# Logistic Regression
# Use the General Linear Model function to build the logistic regression model.
glm.fit <- glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,
data=Smarket,family=binomial)
# Print the summary of the fitted model
summary(glm.fit)
# Generate the probabilyt function based on the fitted model for prediction
glm.probs <- predict(glm.fit,type="response")
# Use the probability function to predict the first five observations in the data
# It will return the probability for going up the next day
glm.probs[1:5]
# We can also use the ifelse() function to change the return values
# If the probabiliyt is over 50%, it will return "Up", else it will return "Down"
glm.pred <- ifelse(glm.probs>0.5,"Up","Down")
# Compare the return values to the previous
# As you observed, the probability function is nested to this new prediction function
glm.pred[1:5]
# We can attach the Smarket data set for convenience
attach(Smarket)
# Check the model prediction to the actual data
table(glm.pred,Direction)
# We can measure the accuracy of the model prediction by taking the mean of the correct results
mean(glm.pred == Direction)
# We can also check the error of the model prediction by reversing the measure
mean(glm.pred != Direction)
# For better accuracy check, we are going to split our data into training and testing sets
# Make training and testing set
# Training data will be the data with year before 2005
train <- Year<2005
# Use the glm() function to build the logistic regression model on the training data
glm.fit <- glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,
data=Smarket,family=binomial, subset=train)
summary(glm.fit)
# Create the probability function by using the fitted model
glm.probs <- predict(glm.fit,newdata=Smarket[!train,],type="response")
# Create the prediction function by defining the results with threshold 50% or above
glm.pred <- ifelse(glm.probs >0.5,"Up","Down")
# Compare the prediction with the testing data
Direction.2005 <- Smarket$Direction[!train]
# Present the comparison in a matrix table
table(glm.pred,Direction.2005)
# Calculate the accuracy for the prediction
mean(glm.pred == Direction.2005)
# We can also find the error rate for the prediction
mean(glm.pred != Direction.2005)
# In the previous model, we found that the lag1 and lag2 are the best predictors in the model
# Let's build a smaller model with just lag1 and lag2 for the logistic regression model
glm.fit <- glm(Direction~Lag1+Lag2,
data=Smarket,family=binomial, subset=train)
glm.probs <- predict(glm.fit,newdata=Smarket[!train,],type="response")
glm.pred <- ifelse(glm.probs >0.5,"Up","Down")
table(glm.pred,Direction.2005)
mean(glm.pred == Direction.2005)
mean(glm.pred != Direction.2005)
# Now, we are going to study the Linear Discriminant Analysis
# The LDA requires the library MASS
require(MASS)
# Linear Discriminant Analysis
# Using lda() function for the linear discriminant analysis with lag1 and lag2
lda.fit <- lda(Direction~Lag1+Lag2,data=Smarket, subset=Year<2005)
# Check the model fit
lda.fit
# Plot the model fit
plot(lda.fit)
# Plot the model fit
plot(lda.fit)
# Define the testing data year = 2005 for testing
Smarket.2005 <- subset(Smarket,Year==2005)
# Use the fitted model to make the prediction using the testing data
lda.pred <- predict(lda.fit,Smarket.2005)
# Predict the first 5 observations
lda.pred$class[1:5]
# Show the prediction in a data frame
data.frame(lda.pred)[1:5,]
# Compare the prediction and testing data in a matrix table
table(lda.pred$class,Smarket.2005$Direction)
# Check the accuracy from the LDA model
mean(lda.pred$class==Smarket.2005$Direction)
# Quadratic Discriminant Analysis
# Using qda() function for the linear discriminant analysis with lag1 and lag2
qda.fit <- qda(Direction~Lag1+Lag2,data=Smarket, subset=Year<2005)
# Check the model fit
qda.fit
library(klaR)
partimat(Direction~Lag1+Lag2,data=Smarket,method="qda")
# Define the testing data year = 2005 for testing
Smarket.2005 <- subset(Smarket,Year==2005)
# Use the fitted model to make the prediction using the testing data
qda.pred <- predict(qda.fit,Smarket.2005)
# Predict the first 5 observations
qda.pred$class[1:5]
print(qda.pred)
# Show the prediction in a data frame
data.frame(lda.pred)[1:5,]
# Compare the prediction and testing data in a matrix table
table(qda.pred$class,Smarket.2005$Direction)
# Check the accuracy from the LDA model
mean(qda.pred$class==Smarket.2005$Direction)
# K-Nearest Neighbors
# The KNN method, we need to import library 'class'
library(class)
# Attached the Smarket data set
attach(Smarket)
# Creating the lag variable, which includes lag1 and lag2
Xlag <- cbind(Lag1,Lag2)
# Create the training data for data before the year 2005
train <- Year<2005
# Use the knn() function to input the training set, testin set, and response variable (Direction)
# Note that we give the parameter k = 1, which defines the number of neighbor
knn.pred <- knn(Xlag[train,],Xlag[!train,],Direction[train],
k=1, prob=FALSE)
# Compare the prediction and the testing data in a matrix table
table(knn.pred,Direction[!train])
# Check the accuracy of the fitted model
mean(knn.pred == Direction[!train])
