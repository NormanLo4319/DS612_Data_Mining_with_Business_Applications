predict.bag = predict(bag.boston, newdata=testingData)
MSE.bag.25Trees = mean((predict.bag - Testing_outcome )^2)
MSE.bag.25Trees #Our error increased
# What if we choose less than 500 trees?
# Let's build a forest with 50 trees
bag.boston = randomForest(medv~., data=trainingData, mtry=13, importance=TRUE, ntree=50)
predict.bag = predict(bag.boston, newdata=testingData)
MSE.bag.50Trees = mean((predict.bag - Testing_outcome )^2)
MSE.bag.50Trees #Our error increased
# Using a for loop to run different size of mtry (number of predictors to be consider for each split of the tree)
MSE.Rf=rep(0,13)
for(d in 1:13){
rf.boston = randomForest(medv~., data=trainingData, mtry=d, importance=TRUE)
predict.rf = predict(rf.boston,newdata = testingData)
MSE.Rf[d] = mean((predict.rf- Testing_outcome )^2)
}
MTRY = c(1:13)
# Plot the MSE for each size of ntry
plot(MTRY,MSE.Rf,type="b",col="red")
min(MSE.Rf)
# mtry=3 created the minimum error - if you repeat this over and over you may get another miminizers such as 4 or 5
rf.boston = randomForest(medv~., data=trainingData, mtry=3, importance=TRUE)
# Getting the prediction from the best model
predict.rf = predict(rf.boston, newdata=testingData)
# Calculate the MSE from the best model
MSE.Rf = mean((predict.rf- Testing_outcome )^2)
MSE.Rf
# Check the importance measures
importance(rf.boston)
# Plot the importance measures
varImpPlot(rf.boston)
library(gbm)
set.seed(1)
# If you are running regression problems then use distribution = "gaussian". If you are working on
# binary classfiication problems, then use distribution = "bernoulli"
# The default value of Lambda is 0.001
boost.boston = gbm(medv~., data=trainingData, distribution="gaussian", n.trees=5000, interaction.depth=4)
boost.boston
summary(boost.boston)
summary(Boston$medv)
# Parial dependence plots for rm and lstat
# These plots illustrate the marginal effect of the selected variables on the response (medv) after
# integerating out the other variables. as we expect medv is increasing with rm and decreasing with lstat
plot(boost.boston,i="rm")
plot(boost.boston,i="lstat")
# Get the prediction from the boosting model
predict.boost = predict(boost.boston, newdata=testingData, n.trees=5000)
# Calculate the MSE of the boosting model
mean((predict.boost-Testing_outcome )^2)
# Let's Change Lambda
Lambda = c(.00001,0.0001,0.001,.01,0.1,.15,.2)
Counter = 1
MSE.Boost = rep(0,7)
# Using a for loop to check different values for Lamda
for(d in Lambda){
boost.boston = gbm(medv~., data=trainingData, distribution="gaussian", n.trees=5000, interaction.depth=4, shrinkage=d)
predict.boost = predict(boost.boston, newdata=testingData, n.trees=5000)
MSE.Boost[Counter] = mean((predict.boost- Testing_outcome )^2)
Counter = Counter + 1
}
# The miminum happened at Lambda = 0.01
plot(Lambda,MSE.Boost,type="b",col="red")
# 17.79736 less than random forest
min(MSE.Boost)
# Now let's fix Lambda and change size of the tree
TreeSize = c(50,100,200,400,500,1000,2000,3000,4000,5000,6000,7000,8000,9000,10000)
Counter = 1
MSE.Boost.Tree = rep(0,15)
# Create a for loop to check different tree size with the best Lamda selected (shrinkage=0.01)
for(d in TreeSize){
boost.boston = gbm(medv~., data=trainingData, distribution="gaussian", n.trees=d, interaction.depth=4, shrinkage=0.01)
predict.boost = predict(boost.boston, newdata=testingData, n.trees=d)
MSE.Boost.Tree[Counter] = mean((predict.boost- Testing_outcome )^2)
Counter = Counter + 1
}
# The tree size reaches miminum at 4000
plot(TreeSize,MSE.Boost.Tree,type="b",col="red")
# it seems like 4000 was a very good choice
min(MSE.Boost.Tree)
MSE.Boost.Tree
data.frame(TreeSize,MSE.Boost.Tree)
# Import the libraries for analysis
library(randomForest)
library(ISLR)
library(tree)
library(MASS)
# Splitting data into training and testing sets (50/50)
set.seed(1)
NumberofObservations = dim(Boston)[1]
SplitofTrainTest = 0.5 #let's split the data 50/50
train = sample(1:NumberofObservations,NumberofObservations*SplitofTrainTest)
test = -train
trainingData = Boston[train,]
testingData  = Boston[test,]
Testing_outcome = Boston$medv[test]
?randomForest
# Bagging is simply a special case of random forest with m = p (All predictors are used to grow trees)
bag.boston = randomForest(medv~., data=trainingData, mtry=13, importance=TRUE)
# mtry is the number of variables randomly sampled as candidates at each slpit.
# The default is sqrt(p) in classification and p/3 in regression
# The default number of trees is 500
bag.boston
names(bag.boston)
summary(bag.boston)
# Using the importance() function to check the importance of each variable
importance(bag.boston)
# We can plot these importance measures with the varImpPlot() function
varImpPlot(bag.boston)
# Make prediction with the trained model by passing in the testing dataset
predict.bag = predict(bag.boston, newdata=testingData)
# Plot the prediction and testing outcome
plot(predict.bag,Testing_outcome)
abline(0,1)
# Calculate the MSE for the bagging model
MSE.bag = mean((predict.bag - Testing_outcome )^2)
MSE.bag
# What if we choose less than 500 trees?
# Let's build a forest with 50 trees
bag.boston = randomForest(medv~., data=trainingData, mtry=13, importance=TRUE, ntree=50)
predict.bag = predict(bag.boston, newdata=testingData)
MSE.bag.50Trees = mean((predict.bag - Testing_outcome )^2)
MSE.bag.50Trees #Our error increased
# What if we choose less than 500 trees?
# Let's build a forest with 50 trees
bag.boston = randomForest(medv~., data=trainingData, mtry=13, importance=TRUE, ntree=50)
predict.bag = predict(bag.boston, newdata=testingData)
MSE.bag.50Trees = mean((predict.bag - Testing_outcome )^2)
MSE.bag.50Trees #Our error increased
for(d in 1:13){
rf.boston = randomForest(medv~., data=trainingData, mtry=d, importance=TRUE)
predict.rf = predict(rf.boston,newdata = testingData)
MSE.Rf[d] = mean((predict.rf- Testing_outcome )^2)
}
# Using a for loop to run different size of mtry (number of predictors to be consider for each split of the tree)
MSE.Rf=rep(0,13)
for(d in 1:13){
rf.boston = randomForest(medv~., data=trainingData, mtry=d, importance=TRUE)
predict.rf = predict(rf.boston,newdata = testingData)
MSE.Rf[d] = mean((predict.rf- Testing_outcome )^2)
}
MTRY = c(1:13)
# Plot the MSE for each size of ntry
plot(MTRY,MSE.Rf,type="b",col="red")
min(MSE.Rf)
data.frame(MTRY, MSE.RF)
data.frame(MTRY, MSE.Rf)
# mtry=3 created the minimum error - if you repeat this over and over you may get another miminizers such as 4 or 5
rf.boston = randomForest(medv~., data=trainingData, mtry=3, importance=TRUE)
# Getting the prediction from the best model
predict.rf = predict(rf.boston, newdata=testingData)
# Calculate the MSE from the best model
MSE.Rf = mean((predict.rf- Testing_outcome )^2)
MSE.Rf
# Check the importance measures
importance(rf.boston)
# Plot the importance measures
varImpPlot(rf.boston)
library(gbm)
set.seed(1)
?gbm
# If you are running regression problems then use distribution = "gaussian". If you are working on
# binary classfiication problems, then use distribution = "bernoulli"
# The default value of Lambda is 0.001 (learning rate of the tree model)
boost.boston = gbm(medv~., data=trainingData, distribution="gaussian", n.trees=5000, interaction.depth=4)
boost.boston
summary(boost.boston)
summary(Boston$medv)
# Parial dependence plots for rm and lstat
# These plots illustrate the marginal effect of the selected variables on the response (medv) after
# integerating out the other variables. as we expect medv is increasing with rm and decreasing with lstat
plot(boost.boston,i="rm")
plot(boost.boston,i="lstat")
?Boston
# Get the prediction from the boosting model
predict.boost = predict(boost.boston, newdata=testingData, n.trees=5000)
# Calculate the MSE of the boosting model
mean((predict.boost-Testing_outcome )^2)
# Let's Change Lambda
Lambda = c(.00001,0.0001,0.001,.01,0.1,.15,.2)
Counter = 1
MSE.Boost = rep(0,7)
# Using a for loop to check different values for Lamda
for(d in Lambda){
boost.boston = gbm(medv~., data=trainingData, distribution="gaussian", n.trees=5000, interaction.depth=4, shrinkage=d)
predict.boost = predict(boost.boston, newdata=testingData, n.trees=5000)
MSE.Boost[Counter] = mean((predict.boost- Testing_outcome )^2)
Counter = Counter + 1
}
# The miminum happened at Lambda = 0.01
plot(Lambda,MSE.Boost,type="b",col="red")
# 17.79736 less than random forest
min(MSE.Boost)
data.frame(Lambda, MSE.Boost)
# Now let's fix Lambda and change size of the tree
TreeSize = c(50,100,200,400,500,1000,2000,3000,4000,5000,6000,7000,8000,9000,10000)
Counter = 1
MSE.Boost.Tree = rep(0,15)
# Create a for loop to check different tree size with the best Lamda selected (shrinkage=0.01)
for(d in TreeSize){
boost.boston = gbm(medv~., data=trainingData, distribution="gaussian", n.trees=d, interaction.depth=4, shrinkage=0.01)
predict.boost = predict(boost.boston, newdata=testingData, n.trees=d)
MSE.Boost.Tree[Counter] = mean((predict.boost- Testing_outcome )^2)
Counter = Counter + 1
}
# The tree size reaches miminum at 4000
plot(TreeSize,MSE.Boost.Tree,type="b",col="red")
# it seems like 4000 was a very good choice
min(MSE.Boost.Tree)
data.frame(TreeSize,MSE.Boost.Tree)
# Remove or clear all memories in the global environment
rm(list=ls(all=TRUE))
# book's Libraray
library(ISLR)
# This libraray is essential to fit decision trees
library(tree)
# The dataset is from ISLR Library
attach(Carseats)
?Carseats
# let's explore the dataset
head(Carseats)
dim(Carseats)
# First let's look up the range for Sales
range(Sales)
# It is from 0 to 16.27
# so, let's split them in half and call high sales for
# Sales more than 8
High = ifelse(Sales >= 8, "Yes", "No")
Carseats = data.frame(Carseats, High)
eats, High)
dim(Carseats)
# Let's get rid of Sales data - Since we already have High
Carseats = Carseats[,-1]
head(Carseats)
#you can set.seed to any number
set.seed(2)
NumberofObservations = nrow(Carseats)
NumberofObservations # that is 400
SplitofTrainTest = 0.5 # let's split the data 50/50
train = sample(1:NumberofObservations,NumberofObservations*SplitofTrainTest)
test = -train
trainingData = Carseats[train,]
testingData  = Carseats[test,]
Testing_outcome = High[test] # The is the our test outcomes
# Now it is the TREE TIME :)
# You need to use training data
Tree_Model = tree(High~., trainingData)
summary(Tree_Model)
plot(Tree_Model) # note there is no text on the tree
text(Tree_Model, pretty=0) # Use pretty = 0 only when you have categorical variables
#Let's check the model based on the test data
Tree_pred = predict(Tree_Model,testingData,type="class") #Since our predictions are on categorical variables we used type = "class"
# Let's compute the error
mean(Tree_pred != Testing_outcome) #0.23
# May be we can do better with pruning
# again, you can set it to any number!
set.seed(1)
# Since we dealt with classification we neede ot set FUN to prune.misclass
cv_tree = cv.tree(Tree_Model, FUN=prune.misclass)
# Size is the size of the tree, Dev is cross-validation error rate
names(cv_tree)
cv_tree
plot(cv_tree$size, cv_tree$dev, type="b")
# Now let's prune our tree - that is the gardening time!
# We pruned our model based on best size we found
pruned_Model = prune.misclass(Tree_Model, best=9)
# in cross-validation - remember it was 9 (you might have found another number)
plot(pruned_Model)
text(pruned_Model, pretty=0)
Tree_pred_new = predict(pruned_Model, testingData, type="class")
mean(Tree_pred_new != Testing_outcome)
# Import the libraries for analysis
library(randomForest)
library(ISLR)
library(tree)
library(MASS)
# We are going to use the Boston data set from MASS library
?Boston
# Splitting data into training and testing sets (50/50)
set.seed(1)
NumberofObservations = dim(Boston)[1]
SplitofTrainTest = 0.5 #let's split the data 50/50
train = sample(1:NumberofObservations,NumberofObservations*SplitofTrainTest)
test = -train
trainingData = Boston[train,]
testingData  = Boston[test,]
Testing_outcome = Boston$medv[test]
?randomForest
dim(Boston)
# Bagging is simply a special case of random forest with m = p (All predictors are used to grow trees)
bag.boston = randomForest(medv~., data=trainingData, mtry=13, importance=TRUE)
# mtry is the number of variables randomly sampled as candidates at each slpit.
# The default is sqrt(p) in classification and p/3 in regression
# The default number of trees is 500
bag.boston
names(bag.boston)
summary(bag.boston)
# Using the importance() function to check the importance of each variable
importance(bag.boston)
# We can plot these importance measures with the varImpPlot() function
varImpPlot(bag.boston)
# Make prediction with the trained model by passing in the testing dataset
predict.bag = predict(bag.boston, newdata=testingData)
# Plot the prediction and testing outcome
plot(predict.bag,Testing_outcome)
abline(0,1)
# Calculate the MSE for the bagging model
MSE.bag = mean((predict.bag - Testing_outcome )^2)
MSE.bag
# What if we choose less than 500 trees?
# Let's build a forest with 50 trees
bag.boston = randomForest(medv~., data=trainingData, mtry=13, importance=TRUE, ntree=50)
predict.bag = predict(bag.boston, newdata=testingData)
MSE.bag.50Trees = mean((predict.bag - Testing_outcome )^2)
MSE.bag.50Trees #Our error increased
# Using a for loop to run different size of mtry (number of predictors to be consider for each split of the tree)
MSE.Rf=rep(0,13)
for(d in 1:13){
rf.boston = randomForest(medv~., data=trainingData, mtry=d, importance=TRUE)
predict.rf = predict(rf.boston,newdata = testingData)
MSE.Rf[d] = mean((predict.rf- Testing_outcome )^2)
}
MTRY = c(1:13)
# Plot the MSE for each size of ntry
plot(MTRY,MSE.Rf,type="b",col="red")
min(MSE.Rf)
data.frame(MTRY, MSE.Rf)
# mtry=3 created the minimum error - if you repeat this over and over you may get another miminizers such as 4 or 5
rf.boston = randomForest(medv~., data=trainingData, mtry=3, importance=TRUE)
# Getting the prediction from the best model
predict.rf = predict(rf.boston, newdata=testingData)
# Calculate the MSE from the best model
MSE.Rf = mean((predict.rf- Testing_outcome )^2)
MSE.Rf
# Check the importance measures
importance(rf.boston)
# Plot the importance measures
varImpPlot(rf.boston)
library(gbm)
set.seed(1)
?gbm
# If you are running regression problems then use distribution = "gaussian". If you are working on
# binary classfiication problems, then use distribution = "bernoulli"
# The default value of Lambda is 0.001 (learning rate of the tree model)
boost.boston = gbm(medv~., data=trainingData, distribution="gaussian", n.trees=5000, interaction.depth=4)
boost.boston
summary(boost.boston)
# Parial dependence plots for rm and lstat
# These plots illustrate the marginal effect of the selected variables on the response (medv) after
# integerating out the other variables. as we expect medv is increasing with rm and decreasing with lstat
plot(boost.boston,i="rm")
plot(boost.boston,i="lstat")
# Get the prediction from the boosting model
predict.boost = predict(boost.boston, newdata=testingData, n.trees=5000)
# Calculate the MSE of the boosting model
mean((predict.boost-Testing_outcome )^2)
# Let's Change Lambda
Lambda = c(.00001,0.0001,0.001,.01,0.1,.15,.2)
Counter = 1
MSE.Boost = rep(0,7)
# Using a for loop to check different values for Lamda
for(d in Lambda){
boost.boston = gbm(medv~., data=trainingData, distribution="gaussian", n.trees=5000, interaction.depth=4, shrinkage=d)
predict.boost = predict(boost.boston, newdata=testingData, n.trees=5000)
MSE.Boost[Counter] = mean((predict.boost- Testing_outcome )^2)
Counter = Counter + 1
}
# The miminum happened at Lambda = 0.01
plot(Lambda,MSE.Boost,type="b",col="red")
data.frame(Lambda, MSE.Boost)
library(ISLR)
attach(Carseats)
library(randomForest)
set.seed(1)
NumberofObservations = nrow(Carseats)
NumberofObservations # that is 400
SplitofTrainTest = 0.5 # let's split the data 50/50
train = sample(1:NumberofObservations,NumberofObservations*SplitofTrainTest)
# train = sample(1:400, 200)
test = -train
trainingData = Carseats[train,]
testingData  = Carseats[test,]
Testing_outcome = Sales[test]
# Check the dimension of the data set
dim(Carseats)
# Use randomForest() function to build a bagging model,
# Remember the bagging model is a special case of Random Forest with m = P
# where m is the max number of predictors use for tree spliting
# and P is the total number of predictors in the data set.
# Use the arguments mtry and importance in the randomForest() function
bag.car = randomForest(Sales~., data=trainingData, mtry=10, importance=TRUE)
#After training the model, make prediction of the response variable with the testing data set.
bag.car.pred = predict(bag.car, newdata=testingData)
# Calcuate the testing mean squared error (MSE)
mean((bag.car.pred-Testing_outcome)^2)
plot(bag.car.pred, Testing_outcome)
abline(0,1)
abline(0,1, color="red")
abline(0,1, color=red)
for n in c(1:11):
print n
for (n in c(1:11)){
print(n)
}
# book's Libraray
library(ISLR)
# The dataset is from ISLR Library
attach(Carseats)
# Import the libraries for analysis
library(randomForest)
# you can set.seed to any number
set.seed(1)
NumberofObservations = nrow(Carseats)
NumberofObservations # that is 400
SplitofTrainTest = 0.5 # let's split the data 50/50
train = sample(1:NumberofObservations,NumberofObservations*SplitofTrainTest)
# train = sample(1:400, 200)
test = -train
trainingData = Carseats[train,]
testingData  = Carseats[test,]
Testing_outcome = Sales[test] # The is the our test outcomes
for (n in(1:11)){
rf.carseats[n] = randomForest(Sales~., data=trainingData, mtry=n)
yhat = predict(rf.carseats[n], newdata=testingData)
MSE.rf.carseats[n] = mean((yhat - test)^2)
}
rf.carseats <- c()
for (n in(1:11)){
rf.carseats[n] = randomForest(Sales~., data=trainingData, mtry=n)
yhat = predict(rf.carseats[n], newdata=testingData)
MSE.rf.carseats[n] = mean((yhat - test)^2)
}
for (n in(1:11)){
rf.carseats = randomForest(Sales~., data=trainingData, mtry=n)
yhat = predict(rf.carseats, newdata=testingData)
MSE.rf.carseats[n] = mean((yhat - test)^2)
}
MSE.rf.carseats <- c()
for (n in(1:11)){
rf.carseats = randomForest(Sales~., data=trainingData, mtry=n)
yhat = predict(rf.carseats, newdata=testingData)
MSE.rf.carseats[n] = mean((yhat - test)^2)
}
mtry <- c(1:11)
plot(mtry, MSE.rf.carseats)
for (n in(1:11)){
rf.carseats = randomForest(Sales~., data=trainingData, mtry=n)
rf.carseats
yhat = predict(rf.carseats, newdata=testingData)
yhat
MSE.rf.carseats[n] = mean((yhat - test)^2)
}
randomForest(Sales~., data=trainingData, mtry=1)
randomForest(Sales~., data=trainingData, mtry=2)
for (n in(1:11)){
rf.carseats = randomForest(Sales~., data=trainingData, mtry=n)
yhat = predict(rf.carseats, newdata=testingData)
MSE.rf.carseats[n] = mean((yhat - Testing_outcome)^2)
}
for (n in c(1:11)){
rf.carseats = randomForest(Sales~., data=trainingData, mtry=n)
yhat = predict(rf.carseats, newdata=testingData)
MSE.rf.carseats[n] = mean((yhat - Testing_outcome)^2)
}
mtry <- c(1:11)
remove(n)
for (n in mtry){
rf.carseats = randomForest(Sales~., data=trainingData, mtry=n)
yhat = predict(rf.carseats, newdata=testingData)
MSE.rf.carseats[n] = mean((yhat - Testing_outcome)^2)
}
?Carseats
dim(Carseats)
mtry <- c(1:10)
for (n in mtry){
rf.carseats = randomForest(Sales~., data=trainingData, mtry=n)
yhat = predict(rf.carseats, newdata=testingData)
MSE.rf.carseats[n] = mean((yhat - Testing_outcome)^2)
}
plot(mtry, MSE.rf.carseats)
mtry <- c(1:10)
plot(mtry, MSE.rf.carseats)
MSE.rf.carseats <- c()
mtry <- c(1:10)
for (n in mtry){
rf.carseats = randomForest(Sales~., data=trainingData, mtry=n)
yhat = predict(rf.carseats, newdata=testingData)
MSE.rf.carseats[n] = mean((yhat - Testing_outcome)^2)
}
plot(mtry, MSE.rf.carseats)
for (n in mtry){
rf.carseats[n] = randomForest(Sales~., data=trainingData, mtry=n)
yhat = predict(rf.carseats[n], newdata=testingData)
MSE.rf.carseats[n] = mean((yhat - Testing_outcome)^2)
}
rf.carseats <- c()
MSE.rf.carseats <- c()
mtry <- c(1:10)
for (n in mtry){
rf.carseats[n] = randomForest(Sales~., data=trainingData, mtry=n)
yhat = predict(rf.carseats[n], newdata=testingData)
MSE.rf.carseats[n] = mean((yhat - Testing_outcome)^2)
}
rf.carseats <- c()
for (n in mtry){
rf.carseats[n] = randomForest(Sales~., data=trainingData, mtry=n)
}
rf.carseats[1]
rf.carseats <- list()
for (n in mtry){
rf.carseats[n] = randomForest(Sales~., data=trainingData, mtry=n)
}
rf.carseats[1]
