rf.boston = randomForest(medv~.,data = trainingData,mtry=d,importance = TRUE)
predict.rf = predict(rf.boston,newdata = testingData)
MSE.Rf[d] = mean((predict.rf- Testing_outcome )^2)
}
for(d in 1:13){
rf.boston = randomForest(medv~., data=trainingData, mtry=d, importance=TRUE)
predict.rf = predict(rf.boston,newdata = testingData)
MSE.Rf[d] = mean((predict.rf- Testing_outcome )^2)
}
MTRY = c(1:13)
plot(MTRY,MSE.Rf,type="b",col="red")
min(MSE.Rf)
#6 created the minimum error - if you repeat this over and over you may get another miminizers such as 4 or 5
rf.boston = randomForest(medv~., data=trainingData, mtry=6, importance=TRUE)
predict.rf = predict(rf.boston, newdata=testingData)
MSE.Rf = mean((predict.rf- Testing_outcome )^2)
MSE.Rf
importance(rf.boston)
varImpPlot(rf.boston)
########################
######  Boosting #######
########################
install.packages("gbm")
library(gbm)  #You must add this library
set.seed(1)
?gbm
#If you are running regression problems then use distribution = "gaussian". If you are working on
#binary classfiication problems, then use distribution = "bernoulli"
#The default value of Lambda is 0.001
boost.boston = gbm(medv~., data=trainingData, distribution="gaussian", n.trees=5000, interaction.depth=4)
boost.boston
summary(boost.boston)
summary(Boston$medv)
#Parial dependence plots for rm and lstat
#These plots illustrate the marginal effect of the selected variables on the response (medv) after
#integerating out the other variables. as we expect medv is increasing with rm and decreasing with lstat
plot(boost.boston,i="rm")
plot(boost.boston,i="lstat")
predict.boost = predict(boost.boston, newdata=testingData, n.trees=5000)
mean((predict.boost-Testing_outcome )^2)
#Let's Change Lambda
Lambda = c(.00001,0.0001,0.001,.01,0.1,.15,.2)
Counter = 1
MSE.Boost = rep(0,7)
for(d in Lambda){
boost.boston = gbm(medv~., data=trainingData, distribution="gaussian", n.trees=5000, interaction.depth=4, shrinkage=d)
predict.boost = predict(boost.boston, newdata=testingData, n.trees=5000)
MSE.Boost[Counter] = mean((predict.boost- Testing_outcome )^2)
Counter = Counter + 1
}
# Plotting the MSE for each Lambda
plot(Lambda,MSE.Boost,type="b",col="red")
min(MSE.Boost)
#Now let's fix Lambda and change size of the tree
TreeSize = c(50,100,200,400,500,1000,2000,3000,4000,5000,6000,7000,8000,9000,10000)
Counter = 1
MSE.Boost.Tree = rep(0,15)
for(d in TreeSize){
boost.boston = gbm(medv~., data=trainingData, distribution="gaussian", n.trees=d, interaction.depth=4, shrinkage=0.01)
predict.boost = predict(boost.boston, newdata=testingData, n.trees=d)
MSE.Boost.Tree[Counter] = mean((predict.boost- Testing_outcome )^2)
Counter = Counter + 1
}
# The miminum happened at Lambda = 0.01
plot(TreeSize,MSE.Boost.Tree,type="b",col="red")
# it seems like 5000 was a very good choice
min(MSE.Boost.Tree)
# Remove all memories in the global environment
rm(list=ls(all=TRUE))
# Loading the required libraries for the lab
require(ISLR)
attach(Wage)
# In this example, we are tyring to predict wages using age from the dataset
# First fit the model using the basic command for polynomial regression
fit.Poly.Basic = lm(wage~age+I(age^2)+I(age^3)+I(age^4),data = Wage)
summary(fit.Poly.Basic)
# We can also use the poly() function to fit the same model
fit.Poly =lm(wage~poly(age,4,raw=TRUE),data = Wage)
summary(fit.Poly)
fit.Poly =lm(wage~poly(age,4),data = Wage)
summary(fit.Poly)
# We can also use the poly() function to fit the same model
fit.Poly =lm(wage~poly(age,4,raw=TRUE),data = Wage)
summary(fit.Poly)
# Note that if we do not define raw=TRUE, the model will still have the same fitted values
# However, the coefficients for each term cannot be interpreted as usual
fit.Poly.Orth =lm(wage~poly(age,4),data = Wage)
summary(fit.Poly.Orth)
# Let's create a grid of valuesfor age for prediction
agelims = range(age)
age.grid=seq(agelims[1],to=agelims[2])
preds = predict(fit.Poly,newdata = list(age=age.grid),se = TRUE)
names(preds)
se.bands = cbind(preds$fit+2*preds$se.fit,preds$fit-2*preds$se.fit)
# Plot the data dn add the fit from the degree-4 polynomial
plot(age,wage,col="darkgray")
lines(age.grid,preds$fit,lwd=2,col="blue") #lwd is linewidth
matlines(age.grid,se.bands,col="blue",lty=2)  #lty shows type of line lty = 2 is used for broken lines
#### Using Anova in Nested sequence of Models ####
fita = lm(wage~education,data = Wage)
fitb = lm(wage~education + age,data = Wage)
fitc = lm(wage~education + poly(age,2),data = Wage)
fitd = lm(wage~education + poly(age,3),data = Wage)
fite = lm(wage~education + poly(age,4),data = Wage)
anova(fita,fitb,fitc,fitd,fite)
#### Logistic Regression ####
fit.Logistics = glm(I(wage>250)~poly(age,3), data=Wage, family=binomial)
summary(fit.Logistics)
preds.Logistics = predict(fit.Logistics, newdata=list(age=age.grid), se=TRUE)
names(preds.Logistics)
se.bands = preds.Logistics$fit+cbind(fit=0, lower=-2*preds.Logistics$se.fit, upper=2*preds.Logistics$se.fit)
se.bands[1:5,]
#Convert logistics to probabilities
prob.bands = exp(se.bands)/(1+exp(se.bands))
prob.bands[1:5,]
matplot(age.grid,prob.bands,col="blue",lwd=c(2,1,1),lty=c(1,2,2),type="l")
#### Fitting step functions ####
# In order to fit a step function, we need to use the cut() function
?cut
table(cut(age,4))
fit.Step = lm(age~cut(age,4),data=Wage)
summary(fit.Step)
#### Splines ####
library(splines)
library(ISLR)
#The bs() function generates the entire matrix of baseis functions for splines
#with the specified set of knots. By default the cubic splines are produced
attach(Wage)
### GAMS ####
install.packages("gam")
library(gam)
# Remove or clear all memories in the global environment
rm(list=ls(all=TRUE))
# book's Libraray
library(ISLR)
# This libraray is essential to fit decision trees
library(tree)
# The dataset is from ISLR Library
attach(Carseats)
# let's explore the dataset
head(Carseats)
# 400 observations 11 variables
dim(Carseats)
summary(ShelveLoc)
# you can set.seed to any number
set.seed(2)
NumberofObservations = nrow(Carseats)
NumberofObservations # that is 400
SplitofTrainTest = 0.5 # let's split the data 50/50
train = sample(1:NumberofObservations,NumberofObservations*SplitofTrainTest)
test = -train
trainingData = Carseats[train,]
testingData  = Carseats[test,]
Testing_outcome = Sales[test] # The is the our test outcomes
# book's Libraray
library(ISLR)
# This libraray is essential to fit decision trees
library(tree)
# The dataset is from ISLR Library
attach(Carseats)
# let's explore the dataset
head(Carseats)
# 400 observations 11 variables
dim(Carseats)
summary(ShelveLoc)
# you can set.seed to any number
set.seed(2)
NumberofObservations = nrow(Carseats)
NumberofObservations # that is 400
SplitofTrainTest = 0.5 # let's split the data 50/50
train = sample(1:NumberofObservations,NumberofObservations*SplitofTrainTest)
test = -train
trainingData = Carseats[train,]
testingData  = Carseats[test,]
Testing_outcome = Sales[test] # The is the our test outcomes
# Now it is the TREE TIME :)
# You need to use training data
Tree_Model = tree(Sales~.,trainingData)
summary(Tree_Model)
# note there is no text on the tree
plot(Tree_Model)
# Use pretty=0 only when you have categorical variables
# (ShelveLoc is a categorical variables)
text(Tree_Model, pretty=0)
# Use pretty=0 only when you have categorical variables
# (ShelveLoc is a categorical variables)
text(Tree_Model)
# note there is no text on the tree
plot(Tree_Model)
# Use pretty=0 only when you have categorical variables
# (ShelveLoc is a categorical variables)
text(Tree_Model)
# note there is no text on the tree
plot(Tree_Model)
# Use pretty=0 only when you have categorical variables
# (ShelveLoc is a categorical variables)
text(Tree_Model, pretty=0)
# Let's check the model based on the test data
Tree_pred = predict(Tree_Model,testingData)
names(Tree_pred)
# Let's compute the error
mean((Tree_pred - Testing_outcome)^2)
# May be we can do better with pruning
# you can set it to any number!
set.seed(3)
# Five fold cross-validation
cv_tree = cv.tree(Tree_Model,K=5)
# Size is the size of the tree, Dev is cross-validation Error
names(cv_tree)
# Our min happened at size=12, you may get a different answer based on your random seeds
plot(cv_tree$size,cv_tree$dev,type="b")
# May be we can do better with pruning
# you can set it to any number!
set.seed(2)
# Five fold cross-validation
cv_tree = cv.tree(Tree_Model,K=5)
# Size is the size of the tree, Dev is cross-validation Error
names(cv_tree)
# Our min happened at size=12, you may get a different answer based on your random seeds
plot(cv_tree$size,cv_tree$dev,type="b")
# May be we can do better with pruning
# you can set it to any number!
set.seed(1)
# Five fold cross-validation
cv_tree = cv.tree(Tree_Model,K=5)
# Size is the size of the tree, Dev is cross-validation Error
names(cv_tree)
# Our min happened at size=12, you may get a different answer based on your random seeds
plot(cv_tree$size,cv_tree$dev,type="b")
# Now let's prune our tree - that is the gardening time!
pruned_Model = prune.tree(Tree_Model, best=12) #We pruned our model based on best size we found
# in cross-validation - remember it was 12 (you might have found another number)
plot(pruned_Model)
text(pruned_Model,pretty=0)
Tree_pred_new = predict(pruned_Model,testingData)
mean((Tree_pred_new - Testing_outcome)^2) #error decreased to 4.667
# May be we can do better with pruning
# you can set it to any number!
set.seed(3)
# Five fold cross-validation
cv_tree = cv.tree(Tree_Model,K=5)
# Size is the size of the tree, Dev is cross-validation Error
names(cv_tree)
# Our min happened at size=12, you may get a different answer based on your random seeds
plot(cv_tree$size,cv_tree$dev,type="b")
# Now let's prune our tree - that is the gardening time!
pruned_Model = prune.tree(Tree_Model, best=10) #We pruned our model based on best size we found
# in cross-validation - remember it was 12 (you might have found another number)
plot(pruned_Model)
text(pruned_Model,pretty=0)
# Let's compute the error
Tree_pred_new = predict(pruned_Model,testingData)
mean((Tree_pred_new - Testing_outcome)^2) #error decreased to 4.676
# Let's compute the error
mean((Tree_pred - Testing_outcome)^2)
# Remove or clear all memories in the global environment
rm(list=ls(all=TRUE))
# book's Libraray
library(ISLR)
# This libraray is essential to fit decision trees
library(tree)
# The dataset is from ISLR Library
attach(Carseats)
# you can set.seed to any number
set.seed(1)
NumberofObservations = nrow(Carseats)
NumberofObservations # that is 400
SplitofTrainTest = 0.5 # let's split the data 50/50
train = sample(1:NumberofObservations,NumberofObservations*SplitofTrainTest)
test = -train
trainingData = Carseats[train,]
testingData  = Carseats[test,]
Testing_outcome = Sales[test] # The is the our test outcomes
# Now it is the TREE TIME :)
# You need to use training data
Tree_Model = tree(Sales~.,trainingData)
summary(Tree_Model)
# note there is no text on the tree
plot(Tree_Model)
# Use pretty=0 only when you have categorical variables
# (ShelveLoc is a categorical variables)
text(Tree_Model, pretty=0)
# Let's check the model based on the test data
Tree_pred = predict(Tree_Model,testingData)
names(Tree_pred)
# Let's compute the error
mean((Tree_pred - Testing_outcome)^2)
# May be we can do better with pruning
# you can set it to any number!
set.seed(1)
# Five fold cross-validation
cv_tree = cv.tree(Tree_Model,K=5)
# Size is the size of the tree, Dev is cross-validation Error
names(cv_tree)
# Our min happened at size=12, you may get a different answer based on your random seeds
plot(cv_tree$size,cv_tree$dev,type="b")
# Now let's prune our tree - that is the gardening time!
pruned_Model = prune.tree(Tree_Model, best=10) #We pruned our model based on best size we found
# in cross-validation - remember it was 12 (you might have found another number)
plot(pruned_Model)
text(pruned_Model,pretty=0)
# Let's compute the error
Tree_pred_new = predict(pruned_Model,testingData)
mean((Tree_pred_new - Testing_outcome)^2) #error decreased to 4.676
# Remove or clear all memories in the global environment
rm(list=ls(all=TRUE))
# Remove or clear all memories in the global environment
rm(list=ls(all=TRUE))
x -> 2
x <- 2
# Remove or clear all memories in the global environment
rm(list=ls(all=TRUE))
# book's Libraray
library(ISLR)
# This libraray is essential to fit decision trees
library(tree)
# The dataset is from ISLR Library
attach(Carseats)
# let's explore the dataset
head(Carseats)
# 400 observations 11 variables
dim(Carseats)
# print summary for catagorical variable "ShelveLoc"
summary(ShelveLoc)
summary(Carseats)
# you can set.seed to any number
set.seed(1)
NumberofObservations = nrow(Carseats)
NumberofObservations # that is 400
SplitofTrainTest = 0.5 # let's split the data 50/50
train = sample(1:NumberofObservations,NumberofObservations*SplitofTrainTest)
test = -train
trainingData = Carseats[train,]
testingData  = Carseats[test,]
Testing_outcome = Sales[test] # The is the our test outcomes
# Now it is the TREE TIME :)
# You need to use training data
Tree_Model = tree(Sales~.,trainingData)
# Tree_Model = tree(Sales~CompPrice+Income+Advertising+...., trainingData)
summary(Tree_Model)
# note there is no text on the tree
plot(Tree_Model)
# Use pretty=0 only when you have categorical variables
# (ShelveLoc is a categorical variables)
text(Tree_Model, pretty=0)
# Let's check the model based on the test data
Tree_pred = predict(Tree_Model,testingData)
names(Tree_pred)
names(Tree_pred[1])
names(Tree_pred['1'])
names(Tree_pred[1])
print(Tree_pred['1'])
print(Tree_pred[1])
# Let's compute the error
mean((Tree_pred - Testing_outcome)^2)
# Five fold cross-validation
# In classification model, you will need to put in the FUN=prune.misclass parameter
cv_tree = cv.tree(Tree_Model,K=5)
# Size is the size of the tree, Dev is cross-validation Error
names(cv_tree)
cv_tree
# Our min happened at size=10, you may get a different answer based on your random seeds
plot(cv_tree$size,cv_tree$dev,type="b")
##### PRUNE THE TREE
# The objective is to reduce the level of overfitting
# May be we can do better with pruning
# you can set it to any number!
set.seed(1)
# Five fold cross-validation
# In classification model, you will need to put in the FUN=prune.misclass parameter
cv_tree = cv.tree(Tree_Model,K=5)
# Size is the size of the tree, Dev is cross-validation Error
names(cv_tree)
cv_tree
# Our min happened at size=10, you may get a different answer based on your random seeds
plot(cv_tree$size,cv_tree$dev,type="b")
# Now let's prune our tree - that is the gardening time!
pruned_Model = prune.tree(Tree_Model, best=9) #We pruned our model based on best size we found
# in cross-validation - remember it was 10 (you might have found another number)
plot(pruned_Model)
text(pruned_Model,pretty=0)
# Let's compute the error
Tree_pred_new = predict(pruned_Model,testingData)
mean((Tree_pred_new - Testing_outcome)^2) #error decreased to 4.918134
# Let's compute the error
mean((Tree_pred - Testing_outcome)^2)
# It is from 0 to 16.27
# so, let's split them in half and call high sales for
# Sales more than 8
High = ifelse(Sales >= 8, "Yes", "No")
Carseats = data.frame(Carseats, High)
dim(Carseats)
# Let's get rid of Sales data - Since we already have High
Carseats = Carseats[,-1]
head(Carseats)
#you can set.seed to any number
set.seed(2)
NumberofObservations = nrow(Carseats)
NumberofObservations # that is 400
SplitofTrainTest = 0.5 # let's split the data 50/50
train = sample(1:NumberofObservations,NumberofObservations*SplitofTrainTest)
test = -train
trainingData = Carseats[train,]
testingData  = Carseats[test,]
Testing_outcome = High[test] # The is the our test outcomes
# Now it is the TREE TIME :)
# You need to use training data
Tree_Model = tree(High~.,trainingData)
plot(Tree_Model) # note there is no text on the tree
text(Tree_Model, pretty = 0) # Use pretty = 0 only when you have categorical variables
#Let's check the model based on the test data
Tree_pred = predict(Tree_Model,testingData,type="class") #Since our predictions are on categorical variables we used type = "class"
# Let's compute the error
mean(Tree_pred != Testing_outcome) #0.23
# Since we dealt with classification we neede ot set FUN to prune.misclass
cv_tree = cv.tree(Tree_Model, FUN=prune.misclass)
# Size is the size of the tree, Dev is cross-validation error rate
names(cv_tree)
plot(cv_tree$size,cv_tree$dev,type="b")
# Now let's prune our tree - that is the gardening time!
# We pruned our model based on best size we found
pruned_Model = prune.misclass(Tree_Model, best=9)
# in cross-validation - remember it was 9 (you might have found another number)
plot(pruned_Model)
text(pruned_Model)
Tree_pred_new = predict(pruned_Model,testingData,type="class")
mean(Tree_pred_new != Testing_outcome)
# Remove or clear all memories in the global environment
rm(list=ls(all=TRUE))
# Remove or clear all memories in the global environment
rm(list=ls(all=TRUE))
# book's Libraray
library(ISLR)
# This libraray is essential to fit decision trees
library(tree)
# The dataset is from ISLR Library
attach(Carseats)
# let's explore the dataset
head(Carseats)
dim(Carseats)
# First let's look up the range for Sales
range(Sales)
# It is from 0 to 16.27
# so, let's split them in half and call high sales for
# Sales more than 8
High = ifelse(Sales >= 8, "Yes", "No")
Carseats = data.frame(Carseats, High)
dim(Carseats)
# Let's get rid of Sales data - Since we already have High
Carseats = Carseats[,-1]
head(Carseats)
#you can set.seed to any number
set.seed(2)
NumberofObservations = nrow(Carseats)
NumberofObservations # that is 400
SplitofTrainTest = 0.5 # let's split the data 50/50
train = sample(1:NumberofObservations,NumberofObservations*SplitofTrainTest)
test = -train
trainingData = Carseats[train,]
testingData  = Carseats[test,]
High[test]
Testing_outcome = High[test] # The is the our test outcomes
# Now it is the TREE TIME :)
# You need to use training data
Tree_Model = tree(High~., trainingData)
summary(Tree_Model)
plot(Tree_Model) # note there is no text on the tree
text(Tree_Model, pretty=0) # Use pretty = 0 only when you have categorical variables
#Let's check the model based on the test data
Tree_pred = predict(Tree_Model,testingData,type="class") #Since our predictions are on categorical variables we used type = "class"
# Let's compute the error
mean(Tree_pred != Testing_outcome) #0.23
# May be we can do better with pruning
# again, you can set it to any number!
set.seed(3)
# Since we dealt with classification we neede ot set FUN to prune.misclass
cv_tree = cv.tree(Tree_Model, FUN=prune.misclass)
# Size is the size of the tree, Dev is cross-validation error rate
names(cv_tree)
cv_tree
plot(cv_tree$size, cv_tree$dev, type="b")
# May be we can do better with pruning
# again, you can set it to any number!
set.seed(2)
# Since we dealt with classification we neede ot set FUN to prune.misclass
cv_tree = cv.tree(Tree_Model, FUN=prune.misclass)
# Size is the size of the tree, Dev is cross-validation error rate
names(cv_tree)
cv_tree
plot(cv_tree$size, cv_tree$dev, type="b")
# May be we can do better with pruning
# again, you can set it to any number!
set.seed(1)
# Since we dealt with classification we neede ot set FUN to prune.misclass
cv_tree = cv.tree(Tree_Model, FUN=prune.misclass)
# Size is the size of the tree, Dev is cross-validation error rate
names(cv_tree)
cv_tree
plot(cv_tree$size, cv_tree$dev, type="b")
# Now let's prune our tree - that is the gardening time!
# We pruned our model based on best size we found
pruned_Model = prune.misclass(Tree_Model, best=9)
# in cross-validation - remember it was 9 (you might have found another number)
plot(pruned_Model)
text(pruned_Model)
# in cross-validation - remember it was 9 (you might have found another number)
plot(pruned_Model)
text(pruned_Model, pretty=0)
Tree_pred_new = predict(pruned_Model, testingData, type="class")
mean(Tree_pred_new != Testing_outcome)
# Let's compute the error
mean(Tree_pred != Testing_outcome) #0.23
