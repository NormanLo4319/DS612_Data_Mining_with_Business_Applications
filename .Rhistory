##Lets write a simple function to use formula (5.2)
loocv = function(fit){
h=lm.influence(fit)$h
mean((residuals(fit)/(1-h))^2)
}
# Now we use the loocv() function to perform the cross validation
loocv(glm.fit)
# We can then use the cross validation function to run glm model for (n - 1) times
# pretty slow (doesnt use formula (5.2) on page 180)
cv.glm(Auto,glm.fit)$delta
# For Cross Validation, we need to import ISLM and Bootstrap
require(ISLR)
require(boot)
# Plot the variables mpg and horsepower from Auto data set
plot(mpg~horsepower,data=Auto)
# Validation Set Approach:
# First create an index for the subset data from the original dataset.
# For instance, we can create a subset of 300 random sample for the dataset.
set.seed(1)
# Validation Set Approach:
# First create an index for the subset data from the original dataset.
# For instance, we can create a subset of 300 random sample for the dataset.
set.seed(12)
# Validation Set Approach:
# First create an index for the subset data from the original dataset.
# For instance, we can create a subset of 300 random sample for the dataset.
set.seed(1)
dim(Auto)[1]
train <- sample(dim(Auto)[1], 300)
train
# Fit the model with the training set
fit1 <- lm(mpg~horsepower, data=Auto, subset=train)
# Calcuate the Mean Square Error for the training set (Train Error)
# mean of (yi - yhat)^2
mean((Auto$mpg-predict(fit1, Auto))[train]^2)
# Calculate the Mean Square Error for the testing set (Test Error)
mean((Auto$mpg-predict(fit1, Auto))[-train]^2)
# We can continue to the do the same thing for quadratic and cubic regressions.
fit2 <- lm(mpg~poly(horsepower, 2), data=Auto, subset=train)
mean((Auto$mpg-predict(fit2, Auto))[train]^2)
mean((Auto$mpg-predict(fit2, Auto))[-train]^2)
fit3 <- lm(mpg~poly(horsepower, 3), data=Auto, subset=train)
mean((Auto$mpg-predict(fit3, Auto))[train]^2)
mean((Auto$mpg-predict(fit3, Auto))[-train]^2)
# We are going to use the cv.glm() function for cross validation
?cv.glm
# We first fit the data into a simple linear model using the glm() function
glm.fit <- glm(mpg~horsepower, data=Auto)
# We can then use the cross validation function to run glm model for (n - 1) times
# pretty slow (doesnt use formula (5.2) on page 180)
cv.glm(Auto,glm.fit)
# We can then use the cross validation function to run glm model for (n - 1) times
# pretty slow (doesnt use formula (5.2) on page 180)
test <- cv.glm(Auto,glm.fit)
test
test$delta
fit <- lm(mpg~horsepower, data=Auto)
mean((Auto$mpg-predict(fit1, Auto))^2)
mean((Auto$mpg-predict(fit, Auto))^2)
cv.glm(Auto, glm.fit)
cv.glm(Auto, glm.fit)$delta
v.glm(Auto, glm.fit)$delta
cv.glm(Auto, glm.fit)$delta
?lm.influence
View(fit)
lm.influence(glm.fit)
lm.influence(glm.fit)$h
##Lets write a simple function to use formula (5.2)
loocv = function(f){
h=lm.influence(f)$h
mean((residuals(f)/(1-h))^2)
}
# Now we use the loocv() function to perform the cross validation
loocv(glm.fit)
cv.glm(Auto, glm.fit)$delta
# Using a for loop to check the the k-fold cross validation comparison
# Try to use 10 cross validation outcomes
cv.error <- rep(0,10)
# Degree of polynomial from 1 to 10
degree <- 1:10
for(d in degree){
glm.fit <- glm(mpg~poly(horsepower,d), data=Auto)
cv.error[d] <- loocv(glm.fit)
}
cv.error
# Plot the cv error and compare different degrees for cross validation
plot(degree,cv.error,type="b")
# Now, let's try to use the 10-fold cross validation
# Try to use 5 cross validation outcomes with degree of polynomial from 1 to 10
cv.error10 <- rep(0,5)
for(d in degree){
glm.fit <- glm(mpg~poly(horsepower, d), data=Auto)
cv.error10[d] <- cv.glm(Auto,glm.fit, K=10)$delta[1]
}
# Plot the line that represents the degree and cv error
lines(degree, cv.error10, type="b", col="red")
for(d in degree){
glm.fit <- glm(mpg~poly(horsepower, d), data=Auto)
cv.error10[d] <- cv.glm(Auto,glm.fit, K=5)$delta[1]
}
# Plot the line that represents the degree and cv error
lines(degree, cv.error10, type="b", col="red")
# Plot the line that represents the degree and cv error
lines(degree, cv.error10, type="b", col="blue")
require(ISLR)
#4.6 Lab: Logistic Regression, LDA, QDA, and KNN
names(Smarket)
summary(Smarket)
pairs(Smarket)
# cor() produces a matrix that contains pairwise correlations among predictors
cor(Smarket) #error, x must be numeric
cor(Smarket[,-9]) #direction variable is qualitative
# correlation between year and volume
attach(Smarket)
plot(Volume) # we see that volume increases over time
# 4.6.2 Logistic Regression
#glm() generalized linear models, must tell r its logistic (family=binomial)
glm.fits=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = Smarket, family = binomial)
summary(glm.fits)
#lag1 has best p-value though it is still quite large
coef(glm.fits) # access just coefficients
summary(glm.fits)$coef # access coefficient table
# predict() used to predict the probability of given values
# predict(type=response) = outputs probabilites of the form P(Y=1|X)
predict(glm.fits) #returns alot of strange things :/
glm.probs=predict(glm.fits,type = "response") #outputs probabilites of the form P(Y=1|X)
glm.probs[1:10] #returns first 10
#convert predicted probabilites into class labels, Up or Down
glm.pred=rep("Down",1250) #creates a vector of 1250 downs, next line assigns the ups
glm.pred[glm.probs>.5]="Up" #creates a vector of class predictions based on probability
#   table() function can be used to create a confusion matrix in order to determin
#   how many objects were correctly or incorrectly classified
table(glm.pred,Direction)
# (507+145)/1250
mean(glm.pred==Direction)
train=(Year<2005)
Smarket.2005=Smarket[!train,]
dim(Smarket.2005)
Direction.2005=Direction[!train]
# fit a logistic regression using only the subset of observations of dates before 2005
glm.fits=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,data = Smarket, family = binomial, subset = train)
glm.probs=predict(glm.fits, Smarket.2005, type = "response")
glm.pred=rep("Down",252)
glm.pred[glm.probs>.5]="UP"
table(glm.pred,Direction.2005)
length(glm.pred)
mean(glm.pred==Direction.2005)
mean(glm.pred!=Direction.2005) #!!!!
glm.probs
Direction.2005
# Import ISLR library
require(ISLR)
# Importing xlsx package for exporting data set to xlsx format
install.packages('xlsx')
library("xlsx")
names(Default)
?Default
write.xlsx(Default, 'Data\\Textbook_Data\\Default.xlsx', row.names=FALSE)
# Call out the Smarket data set
names(Smarket)
# print summary of the data set
summary(Smarket)
# Plot the pairs correlation of the data
pairs(Smarket,col=Smarket$Direction)
# Logistic Regression
# Use the General Linear Model function to build the logistic regression model.
glm.fit <- glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,
data=Smarket,family=binomial)
# Print the summary of the fitted model
summary(glm.fit)
# Generate the probabilyt function based on the fitted model for prediction
glm.probs <- predict(glm.fit,type="response")
# Use the probability function to predict the first five observations in the data
# It will return the probability for going up the next day
glm.probs[1:5]
# We can also use the ifelse() function to change the return values
# If the probabiliyt is over 50%, it will return "Up", else it will return "Down"
glm.pred <- ifelse(glm.probs>0.5,"Up","Down")
# Compare the return values to the previous
# As you observed, the probability function is nested to this new prediction function
glm.pred[1:5]
# We can attach the Smarket data set for convenience
attach(Smarket)
# Check the model prediction to the actual data
table(glm.pred,Direction)
# We can measure the accuracy of the model prediction by taking the mean of the correct results
mean(glm.pred == Direction)
# We can also check the error of the model prediction by reversing the measure
mean(glm.pred != Direction)
# For better accuracy check, we are going to split our data into training and testing sets
# Make training and testing set
# Training data will be the data with year before 2005
train <- Year<2005
# Use the glm() function to build the logistic regression model on the training data
glm.fit <- glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,
data=Smarket,family=binomial, subset=train)
summary(glm.fit)
# Create the probability function by using the fitted model
glm.probs <- predict(glm.fit,newdata=Smarket[!train,],type="response")
# Create the prediction function by defining the results with threshold 50% or above
glm.pred <- ifelse(glm.probs >0.5,"Up","Down")
# Compare the prediction with the testing data
Direction.2005 <- Smarket$Direction[!train]
# Present the comparison in a matrix table
table(glm.pred,Direction.2005)
# Calculate the accuracy for the prediction
mean(glm.pred == Direction.2005)
# fit a logistic regression using only the subset of observations of dates before 2005
glm.fits=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,data = Smarket, family = binomial, subset = train)
summary(glm.fits)
Smarket.2005
Smarket[!train,]
glm.pred
glm.pred
table(glm.pred,Direction.2005)
mean(glm.pred==Direction.2005)
mean(glm.pred!=Direction.2005) #!!!!
# fit a logistic regression using only the subset of observations of dates before 2005
glm.fits=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,data = Smarket, family = binomial, subset = train)
summary(glm.fits)
glm.probs=predict(glm.fits, Smarket.2005, type = "response")
glm.pred=rep("Down",252)
glm.pred[glm.probs>.5]="UP"
glm.pred
mean(glm.pred==Direction.2005)
glm.pred <- ifelse(glm.probs >0.5,"Up","Down")
table(glm.pred,Direction.2005)
mean(glm.pred==Direction.2005)
glm.pred
dtype(glm.pred)
type(glm.pred)
str(glm.pred)
glm.pred=rep("Down",252)
glm.pred[glm.probs>.5]="UP"
str(glm.pred)
glm.pred=rep("Down",252)
glm.pred[glm.probs>.5]="Up"
mean(glm.pred==Direction.2005)
# For Cross Validation, we need to import ISLM and Bootstrap
require(ISLR)
require(boot)
# Plot the variables mpg and horsepower from Auto data set
plot(mpg~horsepower,data=Auto)
# Validation Set Approach:
# First create an index for the subset data from the original dataset.
# For instance, we can create a subset of 300 random sample for the dataset.
set.seed(1)
train <- sample(dim(Auto)[1], 300)
train
# Fit the model with the training set
fit1 <- lm(mpg~horsepower, data=Auto, subset=train)
summary(fit1)
# Calcuate the Mean Square Error for the training set (Train Error)
# MSE = average (yi - yhat)^2
mean((Auto$mpg-predict(fit1, Auto))[train]^2)
# Calculate the Mean Square Error for the testing set (Test Error)
mean((Auto$mpg-predict(fit1, Auto))[-train]^2)
# We can continue to the do the same thing for quadratic and cubic regressions.
fit2 <- lm(mpg~poly(horsepower, 2), data=Auto, subset=train)
summary(fit2)
mean((Auto$mpg-predict(fit2, Auto))[train]^2)
mean((Auto$mpg-predict(fit2, Auto))[-train]^2)
fit3 <- lm(mpg~poly(horsepower, 3), data=Auto, subset=train)
summary(fit3)
mean((Auto$mpg-predict(fit3, Auto))[train]^2)
mean((Auto$mpg-predict(fit3, Auto))[-train]^2)
# We are going to use the cv.glm() function for cross validation
?cv.glm
# We first fit the data into a simple linear model using the glm() function
glm.fit <- glm(mpg~horsepower, data=Auto)
summary(glm.fit)
# We can then use the cross validation function to run glm model for (n - 1) times
# pretty slow (doesnt use formula (5.2) on page 180)
cv.glm(Auto,glm.fit)$delta
##Lets write a simple function to use formula (5.2)
loocv = function(fit){
h=lm.influence(fit)$h
mean((residuals(fit)/(1-h))^2)
}
# Now we use the loocv() function to perform the cross validation
loocv(glm.fit)
# Using a for loop to check the the k-fold cross validation comparison
# e.g.
# n = 400
# k = 10
# in each box, the box will contain a random subset of sample of 40 observations
# Try to use 10 cross validation outcomes
cv.error <- rep(0,10)
# Degree of polynomial from 1 to 10
degree <- 1:10
for(d in degree){
glm.fit <- glm(mpg~poly(horsepower,d), data=Auto)
cv.error[d] <- loocv(glm.fit)
}
cv.error
# Plot the cv error and compare different degrees for cross validation
plot(degree,cv.error,type="b")
# Now, let's try to use the 10-fold cross validation
# Try to use 5 cross validation outcomes with degree of polynomial from 1 to 10
cv.error10 <- rep(0,5)
for(d in degree){
glm.fit <- glm(mpg~poly(horsepower, d), data=Auto)
cv.error10[d] <- cv.glm(Auto,glm.fit, K=10)$delta[1]
}
cv.error10
# Plot the line that represents the degree and cv error
lines(degree, cv.error10, type="b", col="red")
for(d in degree){
glm.fit <- glm(mpg~poly(horsepower, d), data=Auto)
cv.error5[d] <- cv.glm(Auto,glm.fit, K=5)$delta[1]
}
# Try to use 5 cross validation outcomes with degree of polynomial from 1 to 10
cv.error5 <- rep(0,10)
for(d in degree){
glm.fit <- glm(mpg~poly(horsepower, d), data=Auto)
cv.error5[d] <- cv.glm(Auto,glm.fit, K=5)$delta[1]
}
cv.error5
# Plot the line that represents the degree and cv error
lines(degree, cv.error5, type="b", col="blue")
# For Cross Validation, we need to import ISLM and Bootstrap
require(ISLR)
require(boot)
# Plot the variables mpg and horsepower from Auto data set
plot(mpg~horsepower,data=Auto)
# Validation Set Approach:
# First create an index for the subset data from the original dataset.
# For instance, we can create a subset of 300 random sample for the dataset.
set.seed(1)
train <- sample(dim(Auto)[1], 300)
train
# Fit the model with the training set
fit1 <- lm(mpg~horsepower, data=Auto, subset=train)
summary(fit1)
# Calcuate the Mean Square Error for the training set (Train Error)
# MSE = average (yi - yhat)^2
mean((Auto$mpg-predict(fit1, Auto))[train]^2)
# Calculate the Mean Square Error for the testing set (Test Error)
mean((Auto$mpg-predict(fit1, Auto))[-train]^2)
# We can continue to the do the same thing for quadratic and cubic regressions.
fit2 <- lm(mpg~poly(horsepower, 2), data=Auto, subset=train)
summary(fit2)
mean((Auto$mpg-predict(fit2, Auto))[train]^2)
mean((Auto$mpg-predict(fit2, Auto))[-train]^2)
fit3 <- lm(mpg~poly(horsepower, 3), data=Auto, subset=train)
summary(fit3)
mean((Auto$mpg-predict(fit3, Auto))[train]^2)
mean((Auto$mpg-predict(fit3, Auto))[-train]^2)
# We are going to use the cv.glm() function for cross validation
?cv.glm
# We first fit the data into a simple linear model using the glm() function
glm.fit <- glm(mpg~horsepower, data=Auto)
# We can then use the cross validation function to run glm model for (n - 1) times
# pretty slow (doesnt use formula (5.2) on page 180)
cv.glm(Auto,glm.fit)$delta
?lm.influence
##Lets write a simple function to use formula (5.2)
loocv = function(fit){
h=lm.influence(fit)$h
mean((residuals(fit)/(1-h))^2)
}
# Now we use the loocv() function to perform the cross validation
loocv(glm.fit)
# Try to use 10 cross validation outcomes
cv.error <- rep(0,10)
# Degree of polynomial from 1 to 10
degree <- 1:10
for(d in degree){
glm.fit <- glm(mpg~poly(horsepower,d), data=Auto)
cv.error[d] <- loocv(glm.fit)
}
cv.error
# Plot the cv error and compare different degrees for cross validation
plot(degree,cv.error,type="b")
# Now, let's try to use the 10-fold cross validation
# Try to use 5 cross validation outcomes with degree of polynomial from 1 to 10
cv.error10 <- rep(0,10)
for(d in degree){
glm.fit <- glm(mpg~poly(horsepower, d), data=Auto)
cv.error10[d] <- cv.glm(Auto,glm.fit, K=10)$delta[1]
}
cv.error10
# Plot the line that represents the degree and cv error
lines(degree, cv.error10, type="b", col="red")
# Try to use 5-fold cross validation outcomes with degree of polynomial from 1 to 10
cv.error5 <- rep(0,10)
for(d in degree){
glm.fit <- glm(mpg~poly(horsepower, d), data=Auto)
cv.error5[d] <- cv.glm(Auto,glm.fit, K=5)$delta[1]
}
cv.error5
# Plot the line that represents the degree and cv error
lines(degree, cv.error5, type="b", col="blue")
profile
# We are going to use 'Portfolio' data set
?Portfolio
# What is the standard error of alpha?
# We are going to create an alpha function for the analysis
alpha.fn = function(data, index){
X = data$X[index]
Y = data$Y[index]
return((var(Y)-cov(X,Y))/(var(X)+var(Y)-2*cov(X,Y)))
}
require(boot)
# Use the alpha.fn() function to calculate the standard error for alpha
alpha.fn(Portfolio,1:100)
# Set a random seed number
set.seed(1)
# Use the alpha.fn() function again on the 100 sample in the data set
alpha.fn(Portfolio,sample(1:100,100,replace=TRUE))
?boot
# Use boot() function for repeated measures by 1000 times
boot.out <- boot(Portfolio,alpha.fn,R=1000)
boot.out
# Plotting the bootstrap output
plot(boot.out)
# Use boot() function for repeated measures by 1000 times
boot.out <- boot(Portfolio,alpha.fn,R=5000)
boot.out
# Plotting the bootstrap output
plot(boot.out)
# Estimateing the Accuracy of a Linear Regression Model
# Create a boostrap function to pass in the data set and index
boot.fn <- function(data, index){
return(coef(lm(mpg~horsepower, data=data, subset=index)))
}
# Using the bootstrap function to estimate the coefficiencts by defining the subset of data.
# For example, we can define to use all 392 observation from the data.
boot.fn(Auto, 1:392)
# Compare it to the coefficienct with the regular lm() function without specifying subset.
coef(lm(mpg~horsepower, data=Auto))
# Now, let's try to set up a random seed and generate a random sample with replacement.
set.seed(1)
boot_s1 <- sample(392, 392, replace=TRUE)
boot_s1
boot.fn(Auto, boot_s1)
boot_s2 <- sample(392, 392, replace=TRUE)
boot_s2
boot.fn(Auto, boot_s2)
boot.lm <- boot(Auto, boot.fn, R=1000)
boot.lm
plot(boot.lm)
r(lm(mpg~hoursepower,data=auto))
?lm
fitted(lm(mpg~hoursepower,data=auto))
summary(lm(mpg~hoursepower,data=auto))
summary(lm(mpg~hoursepower,data=Auto))
summary(lm(mpg~horsepower,data=Auto))
View(fit1)
View(fit1)
names(summary(lm(mpg~horsepower,data=Auto)))
adj.r.square(lm(mpg~horsepower,data=Auto))
summary(lm(mpg~horsepower,data=Auto))$adj.r.square
boot.r <- function(data,index){
return(summary(lm(mpg~horsepower,data=data, subset=index))$adj.r.square)
}
boot.r <- boot(Auto, boot.r, R=5000)
boot.r
plot(boot.r)
plot(boot.lm, index=2)
plot(boot.lm, index=2)
plot(boot.r)
boot.lm <- boot(Auto, boot.fn, R=5000)
boot.lm
plot(boot.lm, index=2)
# Import ISLR library
require(ISLR)
# Export dataset to csv file
write.csv(Smarket, 'Data\\Textbook_Data\\Smarket.csv', row.names=FALSE)
# Plot the pairs correlation of the data
pairs(Smarket,col=Smarket$Direction)
# Logistic Regression
# Use the General Linear Model function to build the logistic regression model.
glm.fit <- glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,
data=Smarket,family=binomial)
# Print the summary of the fitted model
summary(glm.fit)
glm.probs <- predict(glm.fit,newdata=Smarket[!train,],type="response")
# In the previous model, we found that the lag1 and lag2 are the best predictors in the model
# Let's build a smaller model with just lag1 and lag2 for the logistic regression model
glm.fit <- glm(Direction~Lag1+Lag2,
data=Smarket,family=binomial, subset=train)
glm.probs <- predict(glm.fit,newdata=Smarket[!train,],type="response")
glm.pred <- ifelse(glm.probs >0.5,"Up","Down")
table(glm.pred,Direction.2005)
mean(glm.pred == Direction.2005)
# We can attach the Smarket data set for convenience
attach(Smarket)
# In the previous model, we found that the lag1 and lag2 are the best predictors in the model
# Let's build a smaller model with just lag1 and lag2 for the logistic regression model
glm.fit <- glm(Direction~Lag1+Lag2,
data=Smarket,family=binomial, subset=train)
# For better accuracy check, we are going to split our data into training and testing sets
# Make training and testing set
# Training data will be the data with year before 2005
train <- Year<2005
# In the previous model, we found that the lag1 and lag2 are the best predictors in the model
# Let's build a smaller model with just lag1 and lag2 for the logistic regression model
glm.fit <- glm(Direction~Lag1+Lag2,
data=Smarket,family=binomial, subset=train)
glm.probs <- predict(glm.fit,newdata=Smarket[!train,],type="response")
glm.pred <- ifelse(glm.probs >0.5,"Up","Down")
table(glm.pred,Direction.2005)
# Compare the prediction with the testing data
Direction.2005 <- Smarket$Direction[!train]
table(glm.pred,Direction.2005)
mean(glm.pred == Direction.2005)
mean(glm.pred != Direction.2005)
summary(glm.fit)
Smarket
table(glm.pred,Direction.2005)
mean(glm.pred == Direction.2005)
